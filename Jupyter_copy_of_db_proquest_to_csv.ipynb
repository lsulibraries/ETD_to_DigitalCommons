{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "import urllib.request\n",
    "\n",
    "import openpyxl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts for scrutinizing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_all_sheets(workbook):\n",
    "    # non-essential sanity check function\n",
    "    sheets = [sheet for sheet in available_wb.get_sheet_names()]\n",
    "    print(sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_all_info(urn):\n",
    "    # non-essential script that prints all the info related to a urn.\n",
    "    if urn in main_sheet:\n",
    "        print(\"Main example:\", main_sheet[urn], \"\\n\")\n",
    "    if urn in filenames_sheet:\n",
    "        print(\"Filenames example:\", filenames_sheet[urn], \"\\n\")\n",
    "    if urn in keywords_sheet:\n",
    "        print(\"Keywords example:\", keywords_sheet[urn], \"\\n\")\n",
    "    if urn in advisors_sheet:\n",
    "        print(\"Advisors example:\", advisors_sheet[urn], \"\\n\")\n",
    "    if urn in catalog_sheet:\n",
    "        print(\"Catalog example:\", catalog_sheet[urn], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_combinations_of_advisors(advisors_sheet):\n",
    "    urn_advisortitles = dict()\n",
    "    for urn, advisors_nt_list in advisors_sheet.items():\n",
    "        for item in advisors_nt_list:\n",
    "            if item.urn in urn_advisortitles:\n",
    "                urn_advisortitles[item.urn].append(item.advisor_title)\n",
    "            else:\n",
    "                urn_advisortitles[item.urn] = [item.advisor_title, ]\n",
    "\n",
    "    a_set = set()\n",
    "    for urn, titles in urn_advisortitles.items():\n",
    "        for title in titles:\n",
    "            a_set.add(title)\n",
    "    print(a_set)\n",
    "\n",
    "    advisors_permutations = set()\n",
    "\n",
    "    for urn, titles in urn_advisortitles.items():\n",
    "        this_permutation = (titles.count('Committee Chair'),\n",
    "                            titles.count('Committee Co-Chair'),\n",
    "                            titles.count('Committee Member'),\n",
    "                            titles.count(\"Dean's Representative\"),\n",
    "                            )\n",
    "        advisors_permutations.add(this_permutation)\n",
    "    for i in advisors_permutations:\n",
    "        print(i)\n",
    "    return advisors_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_mismatching_files(filenames_sheet):\n",
    "    sames = dict()\n",
    "    for urn, filenames_namedtuple_list in filenames_sheet.items():\n",
    "        for item in filenames_namedtuple_list:\n",
    "            if item.urn in sames:\n",
    "                if sames[item.urn] != item.availability:\n",
    "                    print('there should be one {}'.format(item.urn))\n",
    "            else:\n",
    "                sames[item.urn] = item.availability\n",
    "    return sames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_misnamed_extensions(filenames_sheet):\n",
    "    misnamed_urn_filename = []\n",
    "    for urn, filenames_namedtuple_list in filenames_sheet.items():\n",
    "        for item in filenames_namedtuple_list:\n",
    "            if item.filename[-4] != \".\" and item.filename[-4:] not in (\"docx\", \"r.gz\"):\n",
    "                misnamed_urn_filename.append((urn, item.filename))\n",
    "                print(urn, item.filename)\n",
    "    return misnamed_urn_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_legacy_school_names(main_sheet):\n",
    "    schools_etds = dict()\n",
    "    for urn, itemnamedtuple in main_sheet.items():\n",
    "        if itemnamedtuple.department in schools_etds:\n",
    "            schools_etds[itemnamedtuple.department].append(urn)\n",
    "        else:\n",
    "            schools_etds[itemnamedtuple.department] = [urn, ]\n",
    "    for school, urns in schools_etds.items():\n",
    "        print(school)\n",
    "    return schools_etds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_page_by_page_pdfs(filenames_sheet):\n",
    "    split_files = dict()\n",
    "    for urn, filenames_namedtuples_list in filenames_sheet.items():\n",
    "        for item in filenames_namedtuples_list:\n",
    "            if item.urn not in split_files:\n",
    "                split_files[item.urn] = [item.filename, ]\n",
    "            else:\n",
    "                split_files[item.urn].append(item.filename)\n",
    "    page_by_page_pdfs = []\n",
    "    for urn, filelist in split_files.items():\n",
    "        split = False\n",
    "        for i in filelist:\n",
    "            if \"chap\" in i.lower():\n",
    "                split = True\n",
    "        if len(filelist) > 1 and split == True:\n",
    "            print(urn, '\\n', filelist, '\\n')\n",
    "            page_by_page_pdfs.append((urn, filelist))\n",
    "    return page_by_page_pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_catalog_subset_of_database(catalog_sheet, main_sheet):\n",
    "    outside_uris = []\n",
    "    for uri in catalog_sheet:\n",
    "        if uri not in main_sheet:\n",
    "            # print(uri)\n",
    "            outside_uris.append(uri)\n",
    "    print(len(outside_uris))\n",
    "    return outside_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def are_all_urns_in_main_sheet(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet):\n",
    "    all_urns = make_set_all_urns(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet)\n",
    "    main_urns = set(i for i in main_sheet)\n",
    "    if (all_urns - main_urns) != set():\n",
    "        print(all_urns - main_urns)\n",
    "    else:\n",
    "        print('all urns in mainsheet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do all files have a pdf, (or no file at all).\n",
    "def check_for_no_file_objects(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet):\n",
    "    no_files = []\n",
    "    for urn in make_set_all_urns(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet):\n",
    "        pdf = False\n",
    "        if urn not in filenames_sheet:\n",
    "            no_files.append(urn)\n",
    "            continue\n",
    "        for nt in filenames_sheet[urn]:\n",
    "            if 'pdf' in nt.filename.lower():\n",
    "                pdf = True\n",
    "        if pdf == False:\n",
    "            print(urn)\n",
    "    print('these have no uploaded files:', no_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading & parsing source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_workbook(workbook_name):\n",
    "    sourcepath = 'data/databasetables'\n",
    "    filename = 'prod_etd_{}_database.xlsx'.format(workbook_name)\n",
    "    fullpath = os.path.join(sourcepath, filename)\n",
    "    return openpyxl.load_workbook(fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_main_sheet(all_db_workbooks):\n",
    "    \"\"\" returns a dictionary in form of:\n",
    "    {urn: NamedTuple\n",
    "     urn: NamedTuple\n",
    "    }\n",
    "    NamedTuple is expected to have attributes: (urn first_name middle_name last_name suffix author_email\n",
    "                                                publish_email degree department dtype title abstract availability\n",
    "                                                availability_description copyright_statement ddate sdate adate\n",
    "                                                cdate rdate pid url notice notice_response timestamp\n",
    "                                                survey_completed)\n",
    "                                            or: (urn first_name middle_name last_name suffix author_email\n",
    "                                                publish_email degree department dtype title abstract availability\n",
    "                                                availability_description copyright_statement ddate sdate adate\n",
    "                                                cdate rdate pid url notices timestamp)\n",
    "    \"\"\"\n",
    "    (available_wb, submitted_wb, withheld_wb) = all_db_workbooks\n",
    "    main_dict = dict()\n",
    "    for wb in (available_wb, submitted_wb, withheld_wb):\n",
    "        current_sheet = wb.get_sheet_by_name('etd_main table')\n",
    "        for num, row in enumerate(current_sheet.iter_rows()):\n",
    "            if num == 0:\n",
    "                headers = (i.value for i in row)\n",
    "                MainSheet = namedtuple('MainSheet', headers)\n",
    "                continue\n",
    "            values = (i.value for i in row)\n",
    "            item = MainSheet(*values)\n",
    "            main_dict[item.urn] = item\n",
    "    return main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_filename_sheet(all_db_workbooks):\n",
    "    \"\"\" returns a dictionary in form of:\n",
    "        urn: [NamedTuple, NamedTuple, ],\n",
    "        urn: [NamedTuple, ]\n",
    "    NamedTuple is expected to have attributes (path, size, availability, description, page_count, timestamp)\n",
    "    \"\"\"\n",
    "    (available_wb, submitted_wb, withheld_wb) = all_db_workbooks\n",
    "    filenames_sheet = dict()\n",
    "    for wb in (available_wb, submitted_wb, withheld_wb):\n",
    "        current_sheet = wb.get_sheet_by_name('filename_by_urn table')\n",
    "        for num, row in enumerate(current_sheet.iter_rows()):\n",
    "            if num == 0:\n",
    "                headers = (i.value for i in row)\n",
    "                Filenames = namedtuple('Filenames', headers)\n",
    "                continue\n",
    "            values = (i.value for i in row)\n",
    "            item = Filenames(*values)\n",
    "\n",
    "            if item.urn not in filenames_sheet:\n",
    "                filenames_sheet[item.urn] = [item, ]\n",
    "            else:\n",
    "                row_timestamp = datetime.strptime(item.timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "                filenames_list = [i.filename for i in filenames_sheet[item.urn]]\n",
    "                if item.filename in filenames_list:\n",
    "                    previous_filename_entry = [i for i in filenames_sheet[item.urn] if i.filename == item.filename]\n",
    "                    previous_timestamp = datetime.strptime(previous_filename_entry[0].timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "                    if row_timestamp > previous_timestamp:\n",
    "                        previous_filename_entry[0] = item\n",
    "                else:\n",
    "                    filenames_sheet[item.urn].append(item)\n",
    "    filenames_sheet = sort_descending_size(filenames_sheet)\n",
    "    return filenames_sheet\n",
    "\n",
    "def sort_descending_size(filenames_sheet):\n",
    "    for urn, list_of_namedtuples in filenames_sheet.items():\n",
    "        list_of_namedtuples = sorted(list_of_namedtuples, key=lambda x:int(x.size), reverse=True)\n",
    "    return filenames_sheet\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_keyword_sheet(all_db_workbooks):\n",
    "    \"\"\" returns a dictionary in form of:\n",
    "    {urn: [NamedTuple,\n",
    "           NamedTuple,\n",
    "           ]}\n",
    "    NamedTuple is expected to have attributes ('keyword', 'urn', 'timestamp')\n",
    "    \"\"\"\n",
    "    (available_wb, submitted_wb, withheld_wb) = all_db_workbooks\n",
    "    keywords_sheet = dict()\n",
    "    for wb in (available_wb, submitted_wb, withheld_wb):\n",
    "        current_sheet = wb.get_sheet_by_name('keyword_by_urn table')\n",
    "        for num, row in enumerate(current_sheet.iter_rows()):\n",
    "            if num == 0:\n",
    "                headers = (i.value for i in row)\n",
    "                Keywords = namedtuple('Keywords', headers)\n",
    "                continue\n",
    "            values = (i.value for i in row)\n",
    "            item = Keywords(*values)\n",
    "            if item.urn not in keywords_sheet:\n",
    "                keywords_sheet[item.urn] = [item, ]\n",
    "            else:\n",
    "                keywords_sheet[item.urn].append(item)\n",
    "    return keywords_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_advisors_sheet(all_db_workbooks):\n",
    "    \"\"\" returns a dictionary in form of:\n",
    "        {urn: [NamedTuple,\n",
    "               NamedTuple,\n",
    "               ]}\n",
    "        NamedTuple is expected to have attributes ('urn', 'advisor_name', 'advisor_title',\n",
    "                                                   'advisor_email', 'approval', 'timestamp')\n",
    "   \"\"\"\n",
    "    advisors_sheet = dict()\n",
    "    (available_wb, submitted_wb, withheld_wb) = all_db_workbooks\n",
    "    for wb in (available_wb, submitted_wb, withheld_wb):\n",
    "        current_sheet = wb.get_sheet_by_name('advisor_by_urn table')\n",
    "        for num, row in enumerate(current_sheet.iter_rows()):\n",
    "            if num == 0:\n",
    "                headers = (i.value for i in row)\n",
    "                Advisors = namedtuple('Advisor', headers)\n",
    "                continue\n",
    "            values = (i.value for i in row)\n",
    "            item = Advisors(*values)\n",
    "            if item.urn not in advisors_sheet:\n",
    "                advisors_sheet[item.urn] = [item, ]\n",
    "            else:\n",
    "                row_timestamp = datetime.strptime(item.timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "                if item.advisor_name in advisors_sheet[item.urn]:\n",
    "                    previous_advisor_entry = [i for i in advisors_sheet[item.urn] if i.advisor_name == item.advisor_name]\n",
    "                    previous_timestamp = datetime.strptime(previous_advisor_entry[0].timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "                    if row_timestamp > previous_timestamp:\n",
    "                        previous_advisor_entry[0] = item\n",
    "                else:\n",
    "                    advisors_sheet[item.urn].append(item)\n",
    "    return advisors_sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_catalog_sheet():\n",
    "    \"\"\" returns a dictionary in form of:\n",
    "        {urn: NamedTuple\n",
    "         urn: NamedTuple}\n",
    "    \"\"\"\n",
    "    catalog_sheet = dict()\n",
    "    sourcepath = 'data/Catalogtables'\n",
    "    sourcefile = 'ETDCatalogRecords20161108.csv'\n",
    "    with open(os.path.join(sourcepath, sourcefile), encoding='utf-8') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter='|')\n",
    "        for num, row in enumerate(csvreader):\n",
    "            if num == 0:\n",
    "                headers = (i for i in row)\n",
    "                Catalog = namedtuple('Catalog', headers)\n",
    "                continue\n",
    "            values = (i for i in row)\n",
    "            item = Catalog(*values)\n",
    "            urn = [i for i in os.path.split(item.URL) if 'etd-' in i]\n",
    "            urn = os.path.split(urn[0])[1]\n",
    "            if not urn:\n",
    "                print('No urn for URL:', item.URL)\n",
    "            else:\n",
    "                catalog_sheet[urn] = item\n",
    "    return catalog_sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_binary(url):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        return response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_binary_to_file(binary, folder, filename):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    with open(filepath, 'bw') as f:\n",
    "        f.write(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_postupload = ('etd-06182004-122626', 'etd-09012004-114224', 'etd-0327102-091522', 'etd-0707103-142120',\n",
    "                     'etd-0710102-054039', 'etd-0409103-184148', 'etd-04152004-142117', 'etd-0830102-145811',\n",
    "                     'etd-0903103-141852', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_binaries(filenames_sheet):\n",
    "    didnt_grab = []\n",
    "    target_dir = './ETDbinaries/'\n",
    "    count = 0\n",
    "    for num, (urn, filenames_namedtuples_list) in enumerate(filenames_sheet.items()):\n",
    "        local_dir = os.path.join(target_dir, urn)\n",
    "        local_files = []\n",
    "        if os.path.isdir(local_dir):\n",
    "            local_files = os.listdir(local_dir)\n",
    "        for item in filenames_namedtuples_list:\n",
    "            if item.filename in local_files:\n",
    "                pass\n",
    "            else:\n",
    "                url = 'http://etd.lsu.edu/{}/{}'.format(\"/\".join(item.path.split('/')[3:]),\n",
    "                                                                 item.filename)\n",
    "                try:\n",
    "                    binary = retrieve_binary(url)\n",
    "                    write_binary_to_file(binary, local_dir, item.filename)\n",
    "                except:\n",
    "                    count += 1\n",
    "                    pass\n",
    "                    didnt_grab.append((urn, item.availability, item.filename))\n",
    "#                     print(urn, item.availability, item.filename)\n",
    "    print(count)\n",
    "    return didnt_grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# didnt_grab = scrape_binaries(filenames_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def what_files_arent_in_ETD_dump():\n",
    "    withheld_files = {file for a,b,c in os.walk('/media/francis/ETD/withheld/') for file in c}\n",
    "    missing_files = set()\n",
    "    for urn, availability, filename in didnt_grab:\n",
    "        if filename in withheld_files:\n",
    "            continue\n",
    "        else:\n",
    "    #         print(urn, availability, filename)\n",
    "            missing_files.add((urn, availability, filename))\n",
    "    return missing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# missing_files = what_files_arent_in_ETD_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(didnt_grab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# missing_list = sorted([*missing_files], key=lambda x:x[0])\n",
    "# for i in missing_list[:10]:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(missing_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ETD_source = [os.path.join(root, file) \n",
    "#               for root, dirs, files in os.walk('/media/francis/ETD/')\n",
    "#               for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for urn, availability, sought_filename in didnt_grab:\n",
    "#     for file in ETD_source:\n",
    "#         found_filename = os.path.split(file)[1]\n",
    "#         found_urn = file.split('/')[5]\n",
    "#         if sought_filename == found_filename and found_urn == urn:\n",
    "#             target_file = os.path.join('./ETDbinaries/', urn, found_filename)\n",
    "#             if not os.path.isfile(target_file):\n",
    "# #                 print(file, target_file)\n",
    "#                 shutil.copy2(file, target_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_writer(data, path):\n",
    "    with open(path, \"w\", newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "        for line in data:\n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatinate_keywords(keywords_sheet, urn):\n",
    "    if urn in keywords_sheet:\n",
    "        return ', '.join(nt.keyword for nt in keywords_sheet[urn] if nt.keyword)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def organize_advisors(advisors_sheet, urn):\n",
    "    Advisor = namedtuple('Advisor', ('urn', 'advisor_name', 'advisor_title',\n",
    "                                           'advisor_email', 'approval', 'timestamp'))\n",
    "    blank_Advisor = Advisor('', '', '', '', '', '')\n",
    "    Advisors_nt = advisors_sheet[urn]\n",
    "    advisors_rank = {'Committee Chair': 1, 'Committee Co-Chair': 2, 'Committee Member': 3, \"Dean's Representative\": 4}\n",
    "    alpha_Advisors = sorted(Advisors_nt, key=lambda x: x.advisor_name)\n",
    "    sorted_advisors = sorted(alpha_Advisors, key=lambda x: advisors_rank[x.advisor_title])\n",
    "    if len(sorted_advisors) > 7 and \"Dean's Representative\" in sorted_advisors[-1]:\n",
    "        sorted_advisors = sorted_advisors[:6] + sorted_advisors[-1:]\n",
    "    elif len(sorted_advisors) > 7:\n",
    "        sorted_advisors = sorted_advisors[:7]\n",
    "    elif len(sorted_advisors) < 7:\n",
    "        missing = 7 - len(sorted_advisors)\n",
    "        for i in range(missing):\n",
    "            sorted_advisors.append(blank_Advisor)\n",
    "    return sorted_advisors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip_slash_and_padding(text):\n",
    "    if not text:\n",
    "        return\n",
    "    text = text.strip()\n",
    "    if text[-1] == '/':\n",
    "        text = text[:-1]\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_null_with_nothing(text):\n",
    "    if not text:\n",
    "        return ''\n",
    "    return text.replace('NULL', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def interpret_publish_email(text):\n",
    "    if text in ('YES', 'NO'):\n",
    "        return text.lower()\n",
    "    else:\n",
    "        return 'NO'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_title(catalog_sheet, main_sheet, urn):\n",
    "    if urn in catalog_sheet:\n",
    "        title = catalog_sheet[urn].Title\n",
    "        title = strip_slash_and_padding(title)\n",
    "        subtitle = catalog_sheet[urn].Subtitle\n",
    "        subtitle = strip_slash_and_padding(subtitle)\n",
    "        if title[-1] == ':':\n",
    "            title = title[:-1]\n",
    "        if subtitle:\n",
    "            csv_title = \"{}:  {}\".format(title,\n",
    "                                         subtitle)\n",
    "        else:\n",
    "            csv_title = title\n",
    "    else:\n",
    "        title = main_sheet[urn].title\n",
    "        title = strip_slash_and_padding(title)\n",
    "        csv_title = title\n",
    "    return csv_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_all_brackets(text):\n",
    "    for i in ('<', '>', '[', ']', '{', '}', '(', ')', '.'):\n",
    "        text = text.replace(i, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_pub_date(catalog_sheet, urn):\n",
    "    if urn in catalog_sheet:\n",
    "        if catalog_sheet[urn].SeriesDate:\n",
    "            return remove_all_brackets(catalog_sheet[urn].SeriesDate)[:4]\n",
    "        if catalog_sheet[urn].PubDate:\n",
    "            return remove_all_brackets(catalog_sheet[urn].PubDate)[:4]\n",
    "    return remove_all_brackets(main_sheet[urn].ddate)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_defense_date(main_sheet, urn):\n",
    "    if main_sheet[urn].ddate:\n",
    "        return remove_all_brackets(main_sheet[urn].ddate)[:4]\n",
    "    return ''\n",
    "\n",
    "def find_submission_date(main_sheet, urn):\n",
    "    if main_sheet[urn].sdate:\n",
    "        return remove_all_brackets(main_sheet[urn].sdate)[:4]\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_filename(filenames_sheet, urn):\n",
    "    if urn in filenames_sheet:\n",
    "        return filenames_sheet[urn][0].filename\n",
    "    return ''\n",
    "\n",
    "def find_filesize(filenames_sheet, urn):\n",
    "    if urn in filenames_sheet:\n",
    "        return filenames_sheet[urn][0].size\n",
    "    return ''\n",
    "\n",
    "def find_filelocation(filenames_sheet, urn):\n",
    "    if urn in filenames_sheet:\n",
    "        return 'not yet implemented'\n",
    "    return 'not yet implemented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_set_all_urns(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet):\n",
    "    all_urns = set()\n",
    "    for sheet in (main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet):\n",
    "        for urn in sheet:\n",
    "            all_urns.add(urn)\n",
    "    all_urns.remove('etd-0807101-102716')  # a test item\n",
    "    all_urns.remove(None)  #\n",
    "    return all_urns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overlooked_degrees = set()\n",
    "\n",
    "def read_legacy_dept_map():\n",
    "    legacy_current = dict()\n",
    "    sourcepath = 'data/LegacyNames.csv'\n",
    "    with open(sourcepath, encoding='utf-8') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter='\\t')\n",
    "        for num, row in enumerate(csvreader):\n",
    "            if num == 0:\n",
    "                headers = (i for i in row)\n",
    "            current, legacy = row[0].strip(), row[1].strip()\n",
    "            if current:\n",
    "                if legacy not in legacy_current:\n",
    "                    if legacy not in ('New', ):\n",
    "                        legacy_current[legacy] = current\n",
    "                else:\n",
    "                    print(legacy, 'has two mappings')\n",
    "    return legacy_current\n",
    "\n",
    "def lookup_current_dept(legacy_dept):\n",
    "    legacy_current = read_legacy_dept_map()\n",
    "    if legacy_dept in legacy_current:\n",
    "        return legacy_current[legacy_dept]\n",
    "    else:\n",
    "        overlooked_degrees.add(legacy_dept)\n",
    "        return legacy_dept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_matching_degree_abbrevs = dict()\n",
    "\n",
    "def make_dict_of_degree_nicknames():\n",
    "    nick_full_dict = dict()\n",
    "    raw_text = \"\"\"Candidate in Philosophy; Doctor of Arts (DA); Doctor of Audiology (AuD); Doctor of Business Administration (DBA); Doctor of Dental Medicine (DMD); Doctor of Education (Ded); Doctor of Education (EdD); Doctor of Engineering (DEng); Doctor of Health and Safety (HSD); Doctor of Management (DMgt); Doctor of Ministry (DMin); Doctor of Music (DM); Doctor of Music Education (DME); Doctor of Musical Arts (DMA); Doctor of Nursing (ND); Doctor of Nursing Science (DNS); Doctor of Pharmacy (PharmD); Doctor of Philosophy (Medical Science); Doctor of Philosophy (PhD); Doctor of Philosophy in Health Services Research (HSOP); Doctor of Physical Education (PED); Doctor of Physical Therapy (DPT); Doctor of Planning and Development Studies (DPDS); Doctor of Psychology (PsyD); Doctor of Public Administration (DPA); Doctor of Public Health (DrPH); Doctor of Recreation (ReD); Doctor of Rehabilitation (RhD); Doctor of Social Work (DSW); Doctor of Veterinary Medicine (DVM); Educat\n",
    " ion Specialist (EdS); International Master of Environmental Sciences (IMES); Juris Doctorate (JD); Master in Advanced Studies (MAS); Master in Agricultural Management (MAM); Master in Management of Technology (MMT); Master in Taxation (MT); Master of Accounting (MAcc); Master of Aeronautical Engineering (MAeroE); Master of Agricultural Education (MAgEd); Master of Agriculture (MAgr); Master of Architectural Engineering (MAE); Master of Architecture (MArch); Master of Architecture (MArch)/Master of Business Administration (MBA); Master of Architecture (MArch)/Master of Fine Arts (MFA); Master of Architecture (MArch)/Master of Urban Planning (MUP); Master of Arts (MA); Master of Arts in Counseling (MAC); Master of Arts in Education (MAE); Master of Arts in Interdisciplinary Studies (MAIS); Master of Arts in Pastoral Counseling (MAPC); Master of Arts in Religion (MAR); Master of Arts in Teaching (MAT); Master of Arts in the Teaching of English (MATE); Master of Biological Scien\n",
    " ce (MBioSci); Master of Building Science (MBS); Master of Business Administration (MBA); Master of Business Administration/Master of Science in Information Systems; Master of Business Taxation (MBT); Master of Career and Technology Education (MCTE); Master of Chemical Engineering (MChE); Master of City and Regional Planning (MCRP); Master of Civil Engineering (MCE); Master of Community Planning; Master of Computer and Information Science (MCIS); Master of Computer Engineering (MCompE); Master of Construction Management (MCM); Master of Construction Science and Management (MCSM); Master of Criminal Justice (MCJ); Master of Divinity (M.Div); Master of Education (MEd); Master of Electrical Engineering (MEE); Master of Electronic Commerce (MECom); Master of Engineering (ME); Master of Engineering (MEngr); Master of Environmental Engineering (MEnvE); Master of Environmental Studies (MES); Master of Fine Arts (MFA); Master of Forest Resources (MFR); Master of Forestry (MF); Master\n",
    "  of General Studies (MGS); Master of Geographic Information Science (MGIS); Master of Geomechanics Engineering (MGeoE); Master of Health Administration (MHA); Master of Historic Preservation (MHP); Master of Historical Administration and Museum Studies (MHAMS); Master of Human Development (MHD); Master of Human Resource Development (MHRD); Master of Interdisciplinary Studies (MIDS); Master of International Management (MIM); Master of Judicial Studies (MJS); Master of Landscape Architecture (MLA); Master of Library Science/Master of Life Sciences (MLS); Master of Management (MM); Master of Materials Science and Engineering (MMatSE); Master of Music (MM); Master of Music (MMUS); Master of Music Education (MME); Master of Parks, Recreation and Tourism Management (MPRTM); Master of Physical Therapy (MPT); Master of Planning (MPlan); Master of Professional Accounting (MPAcc); Master of Public Administration (MPA); Master of Public Administration/Juris Doctorate (MPA/JD); Master o\n",
    " f Public Health (MPH); Master of Public Management (MPM); Master of Public Policy (MPP); Master of Real Estate Development (MRED); Master of Regional Planning (MRP); Master of School Administration (MSA); Master of Science (MS); Master of Science and Software Engineering (MSSE); Master of Science in Acountancy (MSA); Master of Science in Administration (MSA); Master of Science in Aerospace Engineering (MSAeroE); Master of Science in Agricultural Engineering (MSAgE); Master of Science in Biomedical Engineering; Master of Science in Biosystems and Agricultural Engineering (MSBiosyAgE); Master of Science in Chemical Engineering (MSChE); Master of Science in Civil Engineering (MSCE); Master of Science in Community and Regional Planning (MSCRP); Master of Science in Economics (MSECO); Master of Science in Education (MSEd); Master of Science in Electrical and Computer Engineering (MSECE); Master of Science in Electrical Engineering (MSEE); Master of Science in Engineering (MSE); M\n",
    " aster of Science in Engineering Management (MSEM); Master of Science in Environmental Technology Management (MSETM); Master of Science in Hospitality and Tourism Management (MSHTM); Master of Science in Human Resources Management (MSHRM); Master of Science in Industrial Engineering (MSIE); Master of Science in Industrial Engineering and Operations Research (MSIEOR); Master of Science in Information Systems (MSIS); Master of Science in Infrastructure Systems Engineering (MSISE); Master of Science in Interdisciplinary Studies (MSIS); Master of Science in International Business (MSIB); Master of Science in Jurisprudence (MSJ); Master of Science in Management (MSM); Master of Science in Manufacturing Engineering (MSMANFE); Master of Science in Material Science Engineering (MSMatSE); Master of Science in Materials Science and Engineering (MSMSE); Master of Science in Mechanical Engineering (MSME); Master of Science in Medical Sciences (MSMS); Master of Science in Nursing (MSN); M\n",
    " aster of Science in Petroleum Engineering (MSPE); Master of Science in Planning (MSP); Master of Science in Public Health (MSPH); Master of Social Welfare (MSW); Master of Social Work (MSW); Master of Theological Studies (MTS); Master of Theology (Th.M); Master of Urban and Regional Planning (MURP); Master of Urban Planning (MUP); Masters of Health Informatics (MHI); Masters of Science in Bioscience (MSB); Master's of Science in Teaching (MST); Medical Doctor (MD); Medical Surgeon in Experimental Surgery (MSExpSurg); MS Otolaryngology (MSOtol); PhD Otolaryngology (PhDOtol); PhD Surgergy (PhDSurg); Professional Master of Business Administration (PMBA)\"\"\"\n",
    "    for item in raw_text.split(';'):\n",
    "        if '(' not in item:\n",
    "            continue\n",
    "        else:\n",
    "            nick = item.split('(')[1].replace(')','')\n",
    "            name = item\n",
    "            nick_full_dict[nick] = name\n",
    "    return nick_full_dict\n",
    "\n",
    "def expand_degree_type(degree_name):\n",
    "    nick_name_dict = make_dict_of_degree_nicknames()\n",
    "    if degree_name in nick_name_dict:\n",
    "        return nick_name_dict[degree_name]\n",
    "    else:\n",
    "        if degree_name not in non_matching_degree_abbrevs:\n",
    "            non_matching_degree_abbrevs[degree_name] = []\n",
    "#         print('couldnt find a matching degree nickname in expand_degree_type() for {}'.format(degree_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_email(text):\n",
    "    if not text:\n",
    "        return ''\n",
    "    emails = text.split(',')\n",
    "    for i in emails:\n",
    "        if 'lsu.edu' not in i:\n",
    "            return i.strip()\n",
    "    else:\n",
    "        return emails[0].strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# current_department & department mapped -- we need department & legacy department.\n",
    "\n",
    "def build_csv(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet):\n",
    "    csv_data = []\n",
    "    csvfieldnames = [\"title\",\n",
    "                     \"fulltext_url\",\n",
    "                     \"author1_fname\",\n",
    "                     'author1_mname',\n",
    "                     'author1_lname',\n",
    "                     'author1_suffix',\n",
    "                     'author1_email',\n",
    "                     'author1_email_pub',\n",
    "                     'author1_institution',\n",
    "                     'advisor1_title',\n",
    "                     'advisor1',\n",
    "                     \"advisor1_email\",\n",
    "                     'advisor2_title',\n",
    "                     'advisor2',\n",
    "                     \"advisor2_email\",\n",
    "                     'advisor3_title',\n",
    "                     'advisor3',\n",
    "                     \"advisor3_email\",\n",
    "                     'advisor4_title',\n",
    "                     'advisor4',\n",
    "                     \"advisor4_email\",\n",
    "                     'advisor5_title',\n",
    "                     'advisor5',\n",
    "                     \"advisor5_email\",\n",
    "                     'advisor6_title',\n",
    "                     'advisor6',\n",
    "                     \"advisor6_email\",\n",
    "                     'advisor7_title',\n",
    "                     'advisor7',\n",
    "                     \"advisor7_email\",\n",
    "                     \"document_type\",\n",
    "                     'degree_name',\n",
    "                     'legacy_department',\n",
    "                     'department',\n",
    "                     'disciplines',\n",
    "                     'keywords',\n",
    "                     'abstract',\n",
    "                     'publication_date',\n",
    "                     'defense_date',\n",
    "                     'submission_date',\n",
    "                     'availability',\n",
    "                     'availability_description',\n",
    "                     'urn',\n",
    "                     'file_name',\n",
    "                     'file_size',\n",
    "                     'season',\n",
    "                    ]\n",
    "    csv_data.append(csvfieldnames)\n",
    "    all_urns = make_set_all_urns(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet)\n",
    "    for urn in all_urns:\n",
    "        csv_title = combine_title(catalog_sheet, main_sheet, urn)\n",
    "        csv_urn = urn\n",
    "        csv_first_name = main_sheet[urn].first_name\n",
    "        csv_middle_name = main_sheet[urn].middle_name\n",
    "        csv_last_name = main_sheet[urn].last_name\n",
    "        csv_suffix = main_sheet[urn].suffix\n",
    "        csv_suffix = replace_null_with_nothing(csv_suffix)\n",
    "        csv_author_email = split_email(main_sheet[urn].author_email)\n",
    "        csv_publish_email = interpret_publish_email(main_sheet[urn].publish_email)\n",
    "        sorted_advisors = organize_advisors(advisors_sheet, urn)\n",
    "        csv_document_type = main_sheet[urn].dtype.lower()\n",
    "        csv_degree = expand_degree_type(main_sheet[urn].degree)\n",
    "        csv_legacy_department = main_sheet[urn].department\n",
    "        csv_department = lookup_current_dept(main_sheet[urn].department)\n",
    "        csv_disciplines = \"not yet implemented\"\n",
    "        csv_keywords = concatinate_keywords(keywords_sheet, urn)\n",
    "        csv_abstract = main_sheet[urn].abstract\n",
    "        csv_publication_date = find_pub_date(catalog_sheet, urn)\n",
    "        csv_defense_date = find_defense_date(main_sheet, urn)\n",
    "        csv_submission_date = find_submission_date(main_sheet, urn)\n",
    "        csv_availability = main_sheet[urn].availability\n",
    "        csv_availability_desc = main_sheet[urn].availability_description\n",
    "        csv_filename = find_filename(filenames_sheet, urn)\n",
    "        csv_filesize = find_filesize(filenames_sheet, urn)\n",
    "        \n",
    "        \n",
    "        if urn in filenames_sheet:\n",
    "            filename = filenames_sheet[urn][0].filename\n",
    "        else:\n",
    "            filename = ''\n",
    "            \n",
    "        csv_data.append([csv_title,\n",
    "                         '',\n",
    "                         csv_first_name,\n",
    "                         csv_middle_name,\n",
    "                         csv_last_name,\n",
    "                         csv_suffix,\n",
    "                         csv_author_email,\n",
    "                         csv_publish_email,\n",
    "                         'Louisiana State University and Agricultural and Mechanical College',\n",
    "                         sorted_advisors[0].advisor_title,\n",
    "                         sorted_advisors[0].advisor_name,\n",
    "                         sorted_advisors[0].advisor_email,\n",
    "                         sorted_advisors[1].advisor_title,\n",
    "                         sorted_advisors[1].advisor_name,\n",
    "                         sorted_advisors[1].advisor_email,\n",
    "                         sorted_advisors[2].advisor_title,\n",
    "                         sorted_advisors[2].advisor_name,\n",
    "                         sorted_advisors[2].advisor_email,\n",
    "                         sorted_advisors[3].advisor_title,\n",
    "                         sorted_advisors[3].advisor_name,\n",
    "                         sorted_advisors[3].advisor_email,\n",
    "                         sorted_advisors[4].advisor_title,\n",
    "                         sorted_advisors[4].advisor_name,\n",
    "                         sorted_advisors[4].advisor_email,\n",
    "                         sorted_advisors[5].advisor_title,\n",
    "                         sorted_advisors[5].advisor_name,\n",
    "                         sorted_advisors[5].advisor_email,\n",
    "                         sorted_advisors[6].advisor_title,\n",
    "                         sorted_advisors[6].advisor_name,\n",
    "                         sorted_advisors[6].advisor_email,\n",
    "                         csv_document_type,\n",
    "                         csv_degree,\n",
    "                         csv_legacy_department,\n",
    "                         csv_department,\n",
    "                         csv_disciplines,\n",
    "                         csv_keywords,\n",
    "                         csv_abstract,\n",
    "                         csv_publication_date,\n",
    "                         csv_defense_date,\n",
    "                         csv_submission_date,\n",
    "                         csv_availability,\n",
    "                         csv_availability_desc,\n",
    "                         urn,\n",
    "                         csv_filename,\n",
    "                         csv_filesize,\n",
    "                         '',\n",
    "                         ])\n",
    "#     print(csv_data)\n",
    "    csv_writer(csv_data, '../../scrap.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if __name__ == '__main__':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "available_wb = read_workbook('available')\n",
    "submitted_wb = read_workbook('submitted')\n",
    "withheld_wb = read_workbook('withheld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merges the matching sheets from all 3 workbooks into one datastructure per sheet-type.\n",
    "all_db_workbooks = (available_wb, submitted_wb, withheld_wb)\n",
    "\n",
    "main_sheet = parse_main_sheet(all_db_workbooks)\n",
    "filenames_sheet = parse_filename_sheet(all_db_workbooks)\n",
    "keywords_sheet = parse_keyword_sheet(all_db_workbooks)\n",
    "advisors_sheet = parse_advisors_sheet(all_db_workbooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catalog_sheet = parse_catalog_sheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "build_csv(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Construction Management', 'Physics & Astronomy', 'Finance', 'Environmental Sciences', 'English', 'Accounting', 'Management (Business Administration)', 'Chemical Engineering', 'Animal Science (Animal, Dairy, & Poultry Sciences)', 'Landscape Architecture', 'Communication Studies', 'Mass Communication', 'Engineering Science (Interdepartmental Program)', 'Education', 'Foreign Languages & Literatures', 'Entomology', 'Finance (Business Administration)', 'Human Resource Education & Workforce Development', 'Mechanical Engineering', 'Geography & Anthropology', 'Civil & Environmental Engineering', 'Civil and Environmental Engineering', 'Information Systems & Decision Sciences', 'Geology & Geophysics', 'Communication Sciences & Disorders', 'Theatre', 'Educational Leadership, Research & Counseling', 'Plant, Enviromental & Soil Sciences', 'Forestry, Wildlife, and Fisheries', 'Biological Sciences', 'Mathematics', 'Psychology', 'Oceanography and Coastal Sciences', 'Art', 'French Studies', 'Petroleum Engineering', 'Biological & Agricultural Engineering', 'Music', 'Comparative Literature (Interdepartmental Program)', 'Forestry, Wildlife, & Fisheries', 'Composition', 'Textiles, Apparel & Merchandising Design', 'Plant Pathology & Crop Physiology', 'Philosophy & Religious Studies', 'Architecture', 'Experimental Statistics', 'Electrical & Computer Engineering', 'Political Science', 'Social Work', 'Sociology', 'Computer Science', 'Information Systems & Decision Sciences (Business Administration)', 'Dairy Science (Animal, Dairy, and Poultry Sciences)', 'Economics', 'Marketing (Business Administration)', 'Agricultural Economics', 'Educational Leadership, Research and Counseling', 'Dairy Science (Animal, Dairy, & Poultry Sciences)', 'Renewable Natural Resources', 'Veterinary Physiology, Pharmacology, and Toxicology (Veterinary Medical Sciences)', 'Liberal Arts', 'Educational Theory, Policy, & Practice', 'Chemistry', 'Kinesiology', 'History', 'Veterinary Physiology, Pharmacology, & Toxicology (Veterinary Medical Sciences)', 'Human Ecology', 'Natural Sciences (Interdepartmental Program)'}\n"
     ]
    }
   ],
   "source": [
    "print(overlooked_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2193\n"
     ]
    }
   ],
   "source": [
    "main_sheet_urns = {i for i in main_sheet}\n",
    "catalog_sheet_urns = {i for i in catalog_sheet}\n",
    "in_main_not_catalog = main_sheet_urns - catalog_sheet_urns\n",
    "\n",
    "print(len(in_main_not_catalog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for urn, a_list in filenames_sheet.items():\n",
    "#     for nt in a_list:\n",
    "#         if nt.availability not in ('available', 'unrestricted'):\n",
    "#             print(urn, nt.availability, nt.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for urn, pack in main_sheet.items():\n",
    "    if urn in catalog_sheet:\n",
    "        if catalog_sheet[urn].PubDate:\n",
    "            if remove_all_brackets(catalog_sheet[urn].PubDate) != pack.adate[:4]:\n",
    "                count += 1\n",
    "#                 print(urn, remove_all_brackets(catalog_sheet[urn].PubDate), pack.rdate[:4])\n",
    "        elif catalog_sheet[urn].SeriesDate:\n",
    "            if remove_all_brackets(catalog_sheet[urn].SeriesDate) != pack.adate[:4]:\n",
    "                count += 1\n",
    "#                 print(urn, remove_all_brackets(catalog_sheet[urn].SeriesDate), pack.rdate[:4])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etd-1104103-132505\n",
      "etd-11152010-155245\n"
     ]
    }
   ],
   "source": [
    "listed_filenames = set()\n",
    "duplicate_filenames = dict()\n",
    "\n",
    "for urn, item_list in filenames_sheet.items():\n",
    "    for item in item_list:\n",
    "        if item.filename in listed_filenames:\n",
    "            if item.filename in duplicate_filenames:\n",
    "                duplicate_filenames[item.filename] += 1\n",
    "            else:\n",
    "                duplicate_filenames[item.filename] = 1\n",
    "        else:\n",
    "            listed_filenames.add(item.filename)\n",
    "        if item.filename == \"Nelson_thesis.pdf\":\n",
    "            print(urn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Depolarization by Transient Receptor Potential Melastatin 4 in Pancreatic Alpha-Cells Regulates Glucagon Secretion'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_sheet['etd-11152010-155245'].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplicate_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thesis.pdf 45\n",
      "Smith_thesis.pdf 13\n",
      "Kim_dis.pdf 6\n",
      "Lee_dis.pdf 8\n",
      "DISSERTATION.pdf 6\n",
      "Li_dis.pdf 11\n",
      "Johnson_thesis.pdf 6\n",
      "Williams_thesis.pdf 6\n",
      "Wang_thesis.pdf 10\n",
      "thesis.pdf 36\n",
      "Zhang_thesis.pdf 10\n",
      "Li_thesis.pdf 8\n",
      "Zhang_dis.pdf 12\n",
      "Wang_diss.pdf 8\n",
      "THESIS.pdf 13\n",
      "Smith_dis.pdf 6\n",
      "Jones_thesis.pdf 9\n",
      "Johnson_dis.pdf 6\n",
      "Dissertation.pdf 40\n",
      "Wang_dis.pdf 10\n",
      "dissertation.pdf 12\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in duplicate_filenames.items():\n",
    "    if v > 5:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8398\n"
     ]
    }
   ],
   "source": [
    "print(len(main_sheet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
