{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Availables!\n",
    "\n",
    "sourcepath = 'data/databasetables'\n",
    "available_file = 'prod_etd_available_database.xlsx'\n",
    "available_wb = openpyxl.load_workbook(os.path.join(sourcepath, available_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these items' files were chpt-by-chpt pdfs, joined into one pdf post upload.\n",
    "# we must be careful to ingest to Digital Commons the joined files instead of the split files.\n",
    "\n",
    "joined_postupload = ('etd-06182004-122626', 'etd-09012004-114224', 'etd-0327102-091522', 'etd-0707103-142120',\n",
    "                    'etd-0710102-054039', 'etd-0409103-184148', 'etd-04152004-142117', 'etd-0830102-145811',\n",
    "                    'etd-0903103-141852', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prod_etd_available all tables', 'keyword_by_urn table', 'filename_by_urn table', 'etd_main table', 'advisor_by_urn table']\n"
     ]
    }
   ],
   "source": [
    "# list all the sheets within the xsls workbook\n",
    "\n",
    "available_sheets = [sheet for sheet in available_wb.get_sheet_names()]\n",
    "print(available_sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Submitteds!\n",
    "\n",
    "sourcepath = 'data/databasetables'\n",
    "submitted_file = 'prod_etd_submitted_database.xlsx'\n",
    "submitted_wb = openpyxl.load_workbook(os.path.join(sourcepath, submitted_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prod_etd_submitted all tables', 'keyword_by_urn table', 'filename_by_urn table', 'etd_main table', 'advisor_by_urn table']\n"
     ]
    }
   ],
   "source": [
    "submitted_sheets = [sheet for sheet in submitted_wb.get_sheet_names()]\n",
    "print(submitted_sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Withhelds!\n",
    "\n",
    "sourcepath = 'data/databasetables'\n",
    "withheld_file = 'prod_etd_submitted_database.xlsx'\n",
    "withheld_wb = openpyxl.load_workbook(os.path.join(sourcepath, withheld_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prod_etd_submitted all tables', 'keyword_by_urn table', 'filename_by_urn table', 'etd_main table', 'advisor_by_urn table']\n"
     ]
    }
   ],
   "source": [
    "withheld_sheets = [sheet for sheet in withheld_wb.get_sheet_names()]\n",
    "print(withheld_sheets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we've read the Available, Withheld, and Submitted xlsx files into memory.  Everything else is fast now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_main_sheet():\n",
    "    \"\"\" returns a dictionary in form of:\n",
    "    {urn: NamedTuple\n",
    "     urn: NamedTuple\n",
    "    }\n",
    "    NamedTuple is expected to have attributes: (urn first_name middle_name last_name suffix author_email \n",
    "                                                publish_email degree department dtype title abstract availability\n",
    "                                                availability_description copyright_statement ddate sdate adate\n",
    "                                                cdate rdate pid url notice notice_response timestamp\n",
    "                                                survey_completed)\n",
    "                                            or: (urn first_name middle_name last_name suffix author_email\n",
    "                                                publish_email degree department dtype title abstract availability\n",
    "                                                availability_description copyright_statement ddate sdate adate\n",
    "                                                cdate rdate pid url notices timestamp)\n",
    "    )\n",
    "    \"\"\"\n",
    "    main_dict = dict()\n",
    "    for wb in (available_wb, submitted_wb, withheld_wb):\n",
    "        current_sheet = wb.get_sheet_by_name('etd_main table')\n",
    "        for num, row in enumerate(current_sheet.iter_rows()):\n",
    "            if num == 0:\n",
    "                headers = (i.value for i in row)\n",
    "                MainSheet = namedtuple('MainSheet', headers)\n",
    "                continue\n",
    "            values = (i.value for i in row)\n",
    "            item = MainSheet(*values)\n",
    "            main_dict[item.urn] = item\n",
    "    return main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_filename_sheet():\n",
    "    \"\"\"returns a dictionary in form of:\n",
    "    {urn: {filename: (path, size, available, description, page_count, timestamp),\n",
    "           filename: (path, size, available, description, page_count, timestamp),}\n",
    "     urn: {filename: (path, size, available, description, page_count, timestamp),}\n",
    "    \"\"\"\n",
    "    filenames_sheet = dict()\n",
    "    for wb in (available_wb, submitted_wb, withheld_wb):\n",
    "        current_sheet = wb.get_sheet_by_name('filename_by_urn table')\n",
    "        for num, row in enumerate(current_sheet.iter_rows()):\n",
    "            if num == 0:\n",
    "                continue\n",
    "            [urn, filename, path, size, available, description, page_count, timestamp] = [i.value for i in row]\n",
    "            file_dict = {filename: (path, size, available, description, page_count, timestamp)}\n",
    "            if urn not in filenames_sheet:\n",
    "                filenames_sheet[urn] = file_dict\n",
    "            else:\n",
    "                row_timestamp = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "                if filename in filenames_sheet[urn] and filenames_sheet[urn][filename][3] and filenames_sheet[urn][filename][3] != \"NULL\":\n",
    "                    last_timestamp = datetime.strptime(filenames_sheet[urn][filename][3], \"%Y-%m-%d %H:%M:%S\")\n",
    "                    if row_timestamp > last_timestamp:\n",
    "                        filenames_sheet[urn][filename] = (path, size, available, description, page_count, timestamp)\n",
    "                else:\n",
    "                    filenames_sheet[urn][filename] = (path, size, available, description, page_count, timestamp)\n",
    "    return filenames_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_keyword_sheet():\n",
    "    \"\"\" returns a dictionary in form of:\n",
    "    {urn: [(keyword, timestamp),\n",
    "           (keyword, timestamp),\n",
    "           ]}\n",
    "    \"\"\"\n",
    "    keywords_sheet = dict()\n",
    "    for wb in (available_wb, submitted_wb, withheld_wb):\n",
    "        current_sheet = wb.get_sheet_by_name('keyword_by_urn table')\n",
    "        for num, row in enumerate(current_sheet.iter_rows()):\n",
    "            if num == 0:\n",
    "                continue\n",
    "            [keyword, urn, timestamp] = [i.value for i in row]\n",
    "            if urn not in keywords_sheet:\n",
    "                keywords_sheet[urn] = [(keyword, timestamp), ]\n",
    "            else:\n",
    "                keywords_sheet[urn].append((keyword, timestamp))\n",
    "    return keywords_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_advisors_sheet():\n",
    "    \"\"\" returns a dictionary in form of:\n",
    "        {urn: {advisor: (advisor_title, advisor_email, approval, timestamp),\n",
    "               advisor: (advisor_title, advisor_email, approval, timestamp),}\n",
    "         urn: {advisor: (advisor_title, advisor_email, approval, timestamp),}\n",
    "         }\n",
    "    \"\"\"\n",
    "    advisors_sheet = dict()\n",
    "    for wb in (available_wb, submitted_wb, withheld_wb):\n",
    "        current_sheet = wb.get_sheet_by_name('advisor_by_urn table')\n",
    "        for num, row in enumerate(current_sheet.iter_rows()):\n",
    "            if num == 0:\n",
    "                continue\n",
    "            [urn, advisor_name, advisor_title, advisor_email, approval, timestamp] = [i.value for i in row]\n",
    "            advisor_dict = {advisor_name: (advisor_title, advisor_email, approval, timestamp)}\n",
    "            if urn not in advisors_sheet:\n",
    "                advisors_sheet[urn] = advisor_dict\n",
    "            else:\n",
    "                row_timestamp = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "                if advisor_name in advisors_sheet[urn]:\n",
    "                    last_timestamp = datetime.strptime(advisors_sheet[urn][advisor_name][3], \"%Y-%m-%d %H:%M:%S\")\n",
    "                    if row_timestamp > last_timestamp:\n",
    "                        advisors_sheet[urn][advisor_name] = (advisor_title, advisor_email, approval, timestamp)\n",
    "                else:\n",
    "                    advisors_sheet[urn][advisor_name] = (advisor_title, advisor_email, approval, timestamp)\n",
    "    return advisors_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_catalog_sheet():\n",
    "    catalog_sheet = dict()\n",
    "    sourcepath = 'data/Catalogtables'\n",
    "    sourcefile = 'CatalogETDSelectMetadata.csv'\n",
    "    with open(os.path.join(sourcepath, sourcefile)) as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter=',')\n",
    "        count = 0\n",
    "        for num, row in enumerate(csvreader):\n",
    "            if num == 0:\n",
    "                continue\n",
    "            # row = [i.strip('/').strip(']').strip('[').replace('])', '').replace('\\n', '') for i in row]\n",
    "            Title, Subtitle, AuthorFromTitleField, Author, SeriesDate, PubDate, URL = row\n",
    "            urn = [i for i in URL.split('/') if 'etd-' in i]\n",
    "            urn = urn[0]\n",
    "            if not urn:\n",
    "                print('No urn for URL:', URL)\n",
    "            if urn not in catalog_sheet:\n",
    "                catalog_sheet[urn] = [(Title, Subtitle, AuthorFromTitleField, Author, SeriesDate, PubDate, URL), ]\n",
    "            else:\n",
    "                catalog_sheet[urn].append((Title, Subtitle, AuthorFromTitleField, Author, SeriesDate, PubDate, URL))\n",
    "                count += 1\n",
    "    output_srt = ''\n",
    "    for k, item in catalog_sheet.items():\n",
    "        if len(item) > 1:\n",
    "            output_srt += '\\n{}\\n'.format(k)\n",
    "            for thing in item:\n",
    "                output_srt += '\\n'.join(thing)\n",
    "                output_srt += '\\n'\n",
    "            output_srt += '\\n\\n'\n",
    "    return catalog_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main example: MainSheet(urn='etd-0821101-100809', first_name='Wade', middle_name='R.', last_name='Hampton', suffix=None, author_email='waderhampton@yahoo.com', publish_email='NO', degree='MS', department='Agricultural Economics and Agribusiness', dtype='thesis', title='Trade Flows and Marketing Practices of Louisiana and Gulf States Nurseries', abstract='The markets facing nursery producers have changed dramatically in the past decade. These changes in nursery markets have outdated previous research. New research into nursery marketing will assist nursery producers in making marketing decisions. Nursery producers can market their plants to five different marketing channels: Mass-merchandisers, garden centers, other retailers, landscapers and re-wholesalers. This study described the 1998 Louisiana nursery industry, analyzed nursery market changes over the past decade in Louisiana and the Southeast and analyzed characteristics of Louisiana and Southeastern nurseries to estimate marketing channel choice. Data was collected via mail using the third Trade Flows and Marketing Practices survey. Non-respondents to the mail survey were contacted by telephone to obtain survey information. The resulting data set was compiled and tabulated to form a description of the 1998 Louisiana nursery industry. Data from the 1998 TFMP survey was compared with data from the 1988 and 1993 surveys. An analysis of variance for each of the marketing channels was performed to determine if and how marketing channel use had changed over the decade. In order to estimate marketing channel use, a model was designed with the proportion of sales through each channel as a function of a set of market oriented variables such as sales, acreage, age, contract sales, transaction methods, in-state sales and sales to four or more marketing channels . A system of five equations was designed to estimate marketing channel use, one equation for each marketing channel. Analysis of the Louisiana nursery market over the past decade showed that Louisiana nurseries have increased sales to retailers and re-wholesalers at the expense of landscapers. Analysis of nursery marketing channel choice revealed that nurseries have little market power to make marketing decisions. It appears that the retailers and the market dictate marketing decisions in the nursery industry.', availability='unrestricted', availability_description='Release the entire work immediately for access worldwide.', copyright_statement='I hereby grant to LSU or its agents the right to archive and to make available my thesis or dissertation in whole or in part in the University Libraries in all forms of media, now or hereafter known. I retain all proprietary rights, such as patent rights. I also retain the right to use in future works (such as articles or books) all or part of this thesis or dissertation.', ddate='2001-07-23', sdate='2001-08-21', adate='2001-09-05', cdate='0000-00-00', rdate='2002-09-05', pid='waderhampton', url='http://etd.lsu.edu/docs/available/etd-0821101-100809/', notices='NULL', timestamp='2008-06-10 11:35:55') \n",
      "\n",
      "Catalog example: [('Trade flows and marketing practices of Louisiana and Gulf States nurseries', '', 'by Wade R. Hampton.', 'Hampton, Wade R.', '2001', '2001]', 'http://etd.lsu.edu/docs/available/etd-0821101-100809/')] \n",
      "\n",
      "Filenames example: {'Hampton_thesis.pdf': ('/export/ETD-db/docs/available/etd-0821101-100809/unrestricted', '879286', 'unrestricted', 'NULL', 'NULL', '2006-07-11 11:05:25')} \n",
      "\n",
      "Keywords example: [('nurseries', '2008-06-10 11:35:55'), ('marketing channels', '2008-06-10 11:35:55')] \n",
      "\n",
      "Advisors example: {'Steven Henning': ('Committee Member', 'shenning@lsu.edu', 'NULL', '2004-05-06 11:20:06'), 'Richard Kazmeierczak': ('Committee Member', 'rkaz@agctr.lsu.edu', 'NULL', '2004-05-06 11:19:58'), 'Roger Hinson': ('Committee Chair', 'rhinson@agctr.lsu.edu', 'NULL', '2004-05-06 11:19:50')} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we just made plans for how to convert the openpyxls datastructure into python datastructures.  Now let's do it.\n",
    "# take note that each sheet gets a slightly different datastructure, as they describe different data.\n",
    "\n",
    "# print an example of each, for later reference.\n",
    "\n",
    "main_sheet = parse_main_sheet()\n",
    "catalog_sheet = parse_catalog_sheet()\n",
    "filenames_sheet = parse_filename_sheet()\n",
    "keywords_sheet = parse_keyword_sheet()\n",
    "advisors_sheet = parse_advisors_sheet()\n",
    "\n",
    "print(\"Main example:\", main_sheet['etd-0821101-100809'], \"\\n\")\n",
    "print(\"Catalog example:\", catalog_sheet['etd-0821101-100809'], \"\\n\")\n",
    "print(\"Filenames example:\", filenames_sheet['etd-0821101-100809'], \"\\n\")\n",
    "print(\"Keywords example:\", keywords_sheet['etd-0821101-100809'], \"\\n\")\n",
    "print(\"Advisors example:\", advisors_sheet['etd-0821101-100809'], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Committee Chair', 'Committee Member', 'Committee Co-Chair', \"Dean's Representative\"}\n",
      "(1, 0, 3, 2)\n",
      "(1, 0, 4, 2)\n",
      "(3, 0, 2, 1)\n",
      "(1, 2, 3, 0)\n",
      "(0, 2, 2, 1)\n",
      "(1, 0, 5, 1)\n",
      "(1, 1, 1, 1)\n",
      "(0, 0, 3, 1)\n",
      "(1, 2, 0, 0)\n",
      "(2, 0, 1, 0)\n",
      "(0, 2, 5, 0)\n",
      "(0, 2, 4, 0)\n",
      "(1, 0, 7, 1)\n",
      "(1, 1, 3, 1)\n",
      "(2, 1, 0, 1)\n",
      "(2, 0, 2, 0)\n",
      "(1, 0, 1, 1)\n",
      "(0, 1, 3, 1)\n",
      "(1, 1, 2, 2)\n",
      "(0, 2, 1, 0)\n",
      "(1, 0, 2, 3)\n",
      "(0, 2, 0, 0)\n",
      "(1, 0, 3, 1)\n",
      "(2, 0, 4, 0)\n",
      "(1, 1, 4, 1)\n",
      "(1, 2, 2, 1)\n",
      "(0, 2, 3, 0)\n",
      "(1, 0, 4, 0)\n",
      "(5, 0, 0, 1)\n",
      "(0, 2, 2, 0)\n",
      "(1, 0, 5, 0)\n",
      "(0, 0, 4, 1)\n",
      "(0, 3, 2, 1)\n",
      "(0, 2, 5, 1)\n",
      "(1, 0, 6, 0)\n",
      "(0, 0, 2, 1)\n",
      "(2, 0, 3, 1)\n",
      "(1, 0, 0, 0)\n",
      "(1, 0, 1, 0)\n",
      "(1, 1, 2, 1)\n",
      "(0, 0, 0, 1)\n",
      "(0, 2, 1, 1)\n",
      "(1, 0, 2, 0)\n",
      "(1, 1, 5, 0)\n",
      "(1, 0, 3, 0)\n",
      "(1, 1, 4, 0)\n",
      "(0, 0, 6, 0)\n",
      "(0, 2, 3, 1)\n",
      "(1, 0, 3, 3)\n",
      "(1, 0, 4, 1)\n",
      "(0, 0, 5, 0)\n",
      "(0, 0, 4, 0)\n",
      "(0, 3, 1, 1)\n",
      "(1, 0, 6, 1)\n",
      "(1, 1, 1, 0)\n",
      "(0, 0, 3, 0)\n",
      "(3, 0, 0, 0)\n",
      "(0, 1, 4, 1)\n",
      "(1, 0, 0, 4)\n",
      "(1, 1, 0, 0)\n",
      "(1, 2, 1, 1)\n",
      "(0, 2, 4, 1)\n",
      "(0, 1, 2, 1)\n",
      "(1, 1, 3, 0)\n",
      "(1, 1, 2, 0)\n",
      "(2, 0, 2, 1)\n",
      "(1, 0, 2, 1)\n",
      "(1, 0, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# investigate the advisors sheet.  What are the permutations of the advisor types in all the etd records?\n",
    "\n",
    "urn_advisortitles = dict()\n",
    "for urn, chunk in advisors_sheet.items():\n",
    "    for advisor, thing in chunk.items():\n",
    "        advisor_title, advisor_email, approval, timestamp = thing\n",
    "        if urn in urn_advisortitles:\n",
    "            urn_advisortitles[urn].append(advisor_title)\n",
    "        else:\n",
    "            urn_advisortitles[urn] = [advisor_title,]\n",
    "\n",
    "a_set = set()\n",
    "for k, v in urn_advisortitles.items():\n",
    "    for i in v:\n",
    "        a_set.add(i)\n",
    "print(a_set)\n",
    "\n",
    "advisors_permutations = set()\n",
    "\n",
    "for k, v in urn_advisortitles.items():\n",
    "    this_permutation = (v.count('Committee Chair'),\n",
    "                        v.count('Committee Co-Chair'),\n",
    "                        v.count('Committee Member'),\n",
    "                        v.count(\"Dean's Representative\"),\n",
    "                       )\n",
    "    advisors_permutations.add(this_permutation)\n",
    "for i in advisors_permutations:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# locates urns without the expected file\n",
    "\n",
    "# also locates items labeled 'available' in one place & 'withheld' in another\n",
    "#   (irrelevant since we're treating these the same)\n",
    "\n",
    "sames = dict()\n",
    "for urn, bunch in filenames_sheet.items():\n",
    "    for filename, (path, size, available, description, page_count, timestamp) in bunch.items():\n",
    "        if urn in sames:\n",
    "            if sames[urn] != available:\n",
    "                print('there should be one {}'.format(urn))\n",
    "        else:\n",
    "            sames[urn] = available\n",
    "\n",
    "# for urn, itemnamedtuple in main_sheet.items():\n",
    "#     if urn not in sames:\n",
    "#         print('{} wasnt in filenames sheet'.format(urn))\n",
    "#     elif sames[urn] != itemnamedtuple.availability:\n",
    "#         print(urn, sames[urn], itemnamedtuple.availability)\n",
    "        \n",
    "# etd-08082016-164729 wasnt in filenames sheet   --  no pdf submitted yet \n",
    "# etd-06092008-192351 unrestricted withheld      --  listed in available & withheld databases\n",
    "# etd-06062010-192030 wasnt in filenames sheet   --  no pdf submitted yet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# files without proper file extension\n",
    "\n",
    "for etd, filenames in filenames_sheet.items():\n",
    "    for filename, _ in filenames.items():\n",
    "        if filename[-4] != \".\" and filename[-4:] not in (\"docx\", \"r.gz\"):\n",
    "            print(etd, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Legacy school names\n",
    "\n",
    "schools_etds = dict()\n",
    "\n",
    "for urn, itemnamedtuple in main_sheet.items():\n",
    "    if itemnamedtuple.department in schools_etds:\n",
    "        schools_etds[itemnamedtuple.department].append(urn)\n",
    "    else:\n",
    "        schools_etds[itemnamedtuple.department] = [urn, ]\n",
    "\n",
    "# for school, urns in schools_etds.items():\n",
    "#     print(school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Files split into parts\n",
    "\n",
    "split_files = dict()\n",
    "\n",
    "for urn, bunch in filenames_sheet.items():\n",
    "    for filename, _ in bunch.items():\n",
    "        if urn not in split_files:\n",
    "            split_files[urn] = [filename,]\n",
    "        else:\n",
    "            split_files[urn].append(filename)\n",
    "\n",
    "for urn, filelist in split_files.items():\n",
    "    split = False\n",
    "    for i in filelist:\n",
    "        if \"chap\" in i.lower():\n",
    "            split = True\n",
    "    if len(filelist) > 1 and split == True:\n",
    "        print(urn, '\\n', filelist, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scripts for scraping binaries from the webpage to our local drive\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "def retrieve_binary(url, filename):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        return response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_binary_to_file(binary, folder, filename):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    with open(filepath, 'bw') as f:\n",
    "        f.write(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scrape all the binaries\n",
    "\n",
    "# import os\n",
    "\n",
    "# didnt_grab = []\n",
    "# target_dir = '/home/francis/Desktop/ETDbinaries/'\n",
    "\n",
    "# for urn, filebunch in filenames_sheet.items():\n",
    "#     local_dir = os.path.join(target_dir, urn)\n",
    "#     os.makedirs(local_dir, exist_ok=True)\n",
    "#     local_files = os.listdir(local_dir)\n",
    "#     for filename, (path, size, available, description, page_count, timestamp) in filebunch.items():\n",
    "#         if filename in local_files:\n",
    "#             pass\n",
    "#         else:\n",
    "#             url = 'http://etd.lsu.edu/{}/{}'.format(\"/\".join(path.split('/')[3:]), filename)\n",
    "#             try:\n",
    "#                 binary = retrieve_binary(url, filename)\n",
    "#                 write_binary_to_file(binary, local_dir, filename)\n",
    "#             except:\n",
    "#                 didnt_grab.append((urn, filename))\n",
    "#                 print(urn, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper script that prints all the info related to a urn.\n",
    "\n",
    "def show_all_info(urn):\n",
    "    print(\"Main example:\", main_sheet[urn], \"\\n\")\n",
    "    print(\"Filenames example:\", filenames_sheet[urn], \"\\n\")\n",
    "    print(\"Keywords example:\", keywords_sheet[urn], \"\\n\")\n",
    "    print(\"Advisors example:\", advisors_sheet[urn], \"\\n\")\n",
    "    print(\"Catalog example:\", catalog_sheet[urn], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prints the urn, file location, and filename for urns of which we couldn't grab the binaries\n",
    "\n",
    "# for urn, filename in didnt_grab:\n",
    "#     print(urn, filenames_sheet[urn][filename][0], filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show_all_info('etd-09012004-114224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
