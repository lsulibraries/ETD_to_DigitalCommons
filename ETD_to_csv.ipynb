{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts for scrutinizing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "import urllib.request\n",
    "import re\n",
    "\n",
    "import openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_all_sheets(workbook):\n",
    "    # non-essential sanity check function\n",
    "    sheets = [sheet for sheet in available_wb.get_sheet_names()]\n",
    "    print(sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_all_info(urn):\n",
    "    # non-essential script that prints all the info related to a urn.\n",
    "    if urn in main_sheet:\n",
    "        print(\"Main example:\", main_sheet[urn], \"\\n\")\n",
    "    if urn in filenames_sheet:\n",
    "        print(\"Filenames example:\", filenames_sheet[urn], \"\\n\")\n",
    "    if urn in keywords_sheet:\n",
    "        print(\"Keywords example:\", keywords_sheet[urn], \"\\n\")\n",
    "    if urn in advisors_sheet:\n",
    "        print(\"Advisors example:\", advisors_sheet[urn], \"\\n\")\n",
    "    if urn in catalog_sheet:\n",
    "        print(\"Catalog example:\", catalog_sheet[urn], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_combinations_of_advisors(advisors_sheet):\n",
    "    urn_advisortitles = dict()\n",
    "    for urn, advisors_nt_list in advisors_sheet.items():\n",
    "        for item in advisors_nt_list:\n",
    "            if item.urn in urn_advisortitles:\n",
    "                urn_advisortitles[item.urn].append(item.advisor_title)\n",
    "            else:\n",
    "                urn_advisortitles[item.urn] = [item.advisor_title, ]\n",
    "\n",
    "    a_set = set()\n",
    "    for urn, titles in urn_advisortitles.items():\n",
    "        for title in titles:\n",
    "            a_set.add(title)\n",
    "    print(a_set)\n",
    "\n",
    "    advisors_permutations = set()\n",
    "\n",
    "    for urn, titles in urn_advisortitles.items():\n",
    "        this_permutation = (titles.count('Committee Chair'),\n",
    "                            titles.count('Committee Co-Chair'),\n",
    "                            titles.count('Committee Member'),\n",
    "                            titles.count(\"Dean's Representative\"),\n",
    "                            )\n",
    "        advisors_permutations.add(this_permutation)\n",
    "    for i in advisors_permutations:\n",
    "        print(i)\n",
    "    return advisors_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_mismatching_files(filenames_sheet):\n",
    "    sames = dict()\n",
    "    for urn, filenames_namedtuple_list in filenames_sheet.items():\n",
    "        for item in filenames_namedtuple_list:\n",
    "            if item.urn in sames:\n",
    "                if sames[item.urn] != item.availability:\n",
    "                    print('there should be one {}'.format(item.urn))\n",
    "            else:\n",
    "                sames[item.urn] = item.availability\n",
    "    return sames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_misnamed_extensions(filenames_sheet):\n",
    "    misnamed_urn_filename = []\n",
    "    for urn, filenames_namedtuple_list in filenames_sheet.items():\n",
    "        for item in filenames_namedtuple_list:\n",
    "            if item.filename[-4] != \".\" and item.filename[-4:] not in (\"docx\", \"r.gz\"):\n",
    "                misnamed_urn_filename.append((urn, item.filename))\n",
    "                print(urn, item.filename)\n",
    "    return misnamed_urn_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_legacy_school_names(main_sheet):\n",
    "    schools_etds = dict()\n",
    "    for urn, itemnamedtuple in main_sheet.items():\n",
    "        if itemnamedtuple.department in schools_etds:\n",
    "            schools_etds[itemnamedtuple.department].append(urn)\n",
    "        else:\n",
    "            schools_etds[itemnamedtuple.department] = [urn, ]\n",
    "    for school, urns in schools_etds.items():\n",
    "        print(school)\n",
    "    return schools_etds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_page_by_page_pdfs(filenames_sheet):\n",
    "    split_files = dict()\n",
    "    for urn, filenames_namedtuples_list in filenames_sheet.items():\n",
    "        for item in filenames_namedtuples_list:\n",
    "            if item.urn not in split_files:\n",
    "                split_files[item.urn] = [item.filename, ]\n",
    "            else:\n",
    "                split_files[item.urn].append(item.filename)\n",
    "    page_by_page_pdfs = []\n",
    "    for urn, filelist in split_files.items():\n",
    "        split = False\n",
    "        for i in filelist:\n",
    "            if \"chap\" in i.lower():\n",
    "                split = True\n",
    "        if len(filelist) > 1 and split == True:\n",
    "            print(urn, '\\n', filelist, '\\n')\n",
    "            page_by_page_pdfs.append((urn, filelist))\n",
    "    return page_by_page_pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_catalog_subset_of_database(catalog_sheet, main_sheet):\n",
    "    outside_uris = []\n",
    "    for uri in catalog_sheet:\n",
    "        if uri not in main_sheet:\n",
    "            # print(uri)\n",
    "            outside_uris.append(uri)\n",
    "    print(len(outside_uris))\n",
    "    return outside_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def are_all_urns_in_main_sheet(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet):\n",
    "    all_urns = make_set_all_urns(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet)\n",
    "    main_urns = set(i for i in main_sheet)\n",
    "    if (all_urns - main_urns) != set():\n",
    "        print(all_urns - main_urns)\n",
    "    else:\n",
    "        print('all urns in mainsheet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do all files have a pdf, (or no file at all).\n",
    "def check_for_no_file_objects(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet):\n",
    "    no_files = []\n",
    "    for urn in make_set_all_urns(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet):\n",
    "        pdf = False\n",
    "        if urn not in filenames_sheet:\n",
    "            no_files.append(urn)\n",
    "            continue\n",
    "        for nt in filenames_sheet[urn]:\n",
    "            if 'pdf' in nt.filename.lower():\n",
    "                pdf = True\n",
    "        if pdf == False:\n",
    "            print(urn)\n",
    "    print('these have no uploaded files:', no_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading & parsing source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_items = ('etd-0807101-102716',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_workbook(workbook_name):\n",
    "    sourcepath = 'data/databasetables'\n",
    "    filename = 'prod_etd_{}_database.xlsx'.format(workbook_name)\n",
    "    fullpath = os.path.join(sourcepath, filename)\n",
    "    return openpyxl.load_workbook(fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_main_sheet(all_db_workbooks):\n",
    "    \"\"\" returns a dictionary in form of:\n",
    "    {urn: NamedTuple\n",
    "     urn: NamedTuple\n",
    "    }\n",
    "    NamedTuple is expected to have attributes: (urn first_name middle_name last_name suffix author_email\n",
    "                                                publish_email degree department dtype title abstract availability\n",
    "                                                availability_description copyright_statement ddate sdate adate\n",
    "                                                cdate rdate pid url notice notice_response timestamp\n",
    "                                                survey_completed)\n",
    "                                            or: (urn first_name middle_name last_name suffix author_email\n",
    "                                                publish_email degree department dtype title abstract availability\n",
    "                                                availability_description copyright_statement ddate sdate adate\n",
    "                                                cdate rdate pid url notices timestamp)\n",
    "    \"\"\"\n",
    "    (available_wb, submitted_wb, withheld_wb) = all_db_workbooks\n",
    "    main_dict = dict()\n",
    "    for wb in (available_wb, submitted_wb, withheld_wb):\n",
    "        current_sheet = wb.get_sheet_by_name('etd_main table')\n",
    "        for num, row in enumerate(current_sheet.iter_rows()):\n",
    "            if num == 0:\n",
    "                headers = (i.value for i in row)\n",
    "                MainSheet = namedtuple('MainSheet', headers)\n",
    "                continue\n",
    "            values = (i.value for i in row)\n",
    "            item = MainSheet(*values)\n",
    "            if item.urn not in test_items:\n",
    "                main_dict[item.urn] = item\n",
    "    return main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_filename_sheet(all_db_workbooks):\n",
    "    \"\"\" returns a dictionary in form of:\n",
    "        urn: [NamedTuple, NamedTuple, ],\n",
    "        urn: [NamedTuple, ]\n",
    "    NamedTuple is expected to have attributes (path, size, availability, description, page_count, timestamp)\n",
    "    \"\"\"\n",
    "    (available_wb, submitted_wb, withheld_wb) = all_db_workbooks\n",
    "    filenames_sheet = dict()\n",
    "    for wb in (available_wb, submitted_wb, withheld_wb):\n",
    "        current_sheet = wb.get_sheet_by_name('filename_by_urn table')\n",
    "        for num, row in enumerate(current_sheet.iter_rows()):\n",
    "            if num == 0:\n",
    "                headers = (i.value for i in row)\n",
    "                Filenames = namedtuple('Filenames', headers)\n",
    "                continue\n",
    "            values = (i.value for i in row)\n",
    "            item = Filenames(*values)\n",
    "            \n",
    "            if item.urn not in test_items:\n",
    "                if item.urn not in filenames_sheet:\n",
    "                    filenames_sheet[item.urn] = [item, ]\n",
    "                else:\n",
    "                    row_timestamp = datetime.strptime(item.timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "                    filenames_list = [i.filename for i in filenames_sheet[item.urn]]\n",
    "                    if item.filename in filenames_list:\n",
    "                        previous_filename_entry = [i for i in filenames_sheet[item.urn] if i.filename == item.filename]\n",
    "                        previous_timestamp = datetime.strptime(previous_filename_entry[0].timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "                        if row_timestamp > previous_timestamp:\n",
    "                            previous_filename_entry[0] = item\n",
    "                    else:\n",
    "                        filenames_sheet[item.urn].append(item)\n",
    "    filenames_sheet = sort_descending_size(filenames_sheet)\n",
    "    return filenames_sheet\n",
    "\n",
    "def sort_descending_size(filenames_sheet):\n",
    "    for urn, list_of_namedtuples in filenames_sheet.items():\n",
    "        list_of_namedtuples = sorted(list_of_namedtuples, key=lambda x:int(x.size), reverse=True)\n",
    "    return filenames_sheet\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_keyword_sheet(all_db_workbooks):\n",
    "    \"\"\" returns a dictionary in form of:\n",
    "    {urn: [NamedTuple,\n",
    "           NamedTuple,\n",
    "           ]}\n",
    "    NamedTuple is expected to have attributes ('keyword', 'urn', 'timestamp')\n",
    "    \"\"\"\n",
    "    (available_wb, submitted_wb, withheld_wb) = all_db_workbooks\n",
    "    keywords_sheet = dict()\n",
    "    for wb in (available_wb, submitted_wb, withheld_wb):\n",
    "        current_sheet = wb.get_sheet_by_name('keyword_by_urn table')\n",
    "        for num, row in enumerate(current_sheet.iter_rows()):\n",
    "            if num == 0:\n",
    "                headers = (i.value for i in row)\n",
    "                Keywords = namedtuple('Keywords', headers)\n",
    "                continue\n",
    "            values = (i.value for i in row)\n",
    "            item = Keywords(*values)\n",
    "            if item.urn not in test_items:\n",
    "                if item.urn not in keywords_sheet:\n",
    "                    keywords_sheet[item.urn] = [item, ]\n",
    "                else:\n",
    "                    keywords_sheet[item.urn].append(item)\n",
    "    return keywords_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_advisors_sheet(all_db_workbooks):\n",
    "    \"\"\" returns a dictionary in form of:\n",
    "        {urn: [NamedTuple,\n",
    "               NamedTuple,\n",
    "               ]}\n",
    "        NamedTuple is expected to have attributes ('urn', 'advisor_name', 'advisor_title',\n",
    "                                                   'advisor_email', 'approval', 'timestamp')\n",
    "   \"\"\"\n",
    "    advisors_sheet = dict()\n",
    "    (available_wb, submitted_wb, withheld_wb) = all_db_workbooks\n",
    "    for wb in (available_wb, submitted_wb, withheld_wb):\n",
    "        current_sheet = wb.get_sheet_by_name('advisor_by_urn table')\n",
    "        for num, row in enumerate(current_sheet.iter_rows()):\n",
    "            if num == 0:\n",
    "                headers = (i.value for i in row)\n",
    "                Advisors = namedtuple('Advisor', headers)\n",
    "                continue\n",
    "            values = (i.value for i in row)\n",
    "            item = Advisors(*values)\n",
    "            if item.urn not in test_items:\n",
    "                if item.urn not in advisors_sheet:\n",
    "                    advisors_sheet[item.urn] = [item, ]\n",
    "                else:\n",
    "                    row_timestamp = datetime.strptime(item.timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "                    if item.advisor_name in advisors_sheet[item.urn]:\n",
    "                        previous_advisor_entry = [i for i in advisors_sheet[item.urn] if i.advisor_name == item.advisor_name]\n",
    "                        previous_timestamp = datetime.strptime(previous_advisor_entry[0].timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "                        if row_timestamp > previous_timestamp:\n",
    "                            previous_advisor_entry[0] = item\n",
    "                    else:\n",
    "                        advisors_sheet[item.urn].append(item)\n",
    "    return advisors_sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_catalog_sheet():\n",
    "    \"\"\" returns a dictionary in form of:\n",
    "        {urn: NamedTuple\n",
    "         urn: NamedTuple}\n",
    "    \"\"\"\n",
    "    catalog_sheet = dict()\n",
    "    sourcepath = 'data/Catalogtables'\n",
    "    sourcefile = 'ETDCatalogRecords20161108.csv'\n",
    "    with open(os.path.join(sourcepath, sourcefile), encoding='utf-8') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter='|')\n",
    "        for num, row in enumerate(csvreader):\n",
    "            if num == 0:\n",
    "                headers = (i for i in row)\n",
    "                Catalog = namedtuple('Catalog', headers)\n",
    "                continue\n",
    "            values = (i for i in row)\n",
    "            item = Catalog(*values)\n",
    "            urn = [i for i in os.path.split(item.URL) if 'etd-' in i]\n",
    "            urn = os.path.split(urn[0])[1]\n",
    "            if urn not in test_items:\n",
    "                catalog_sheet[urn] = item\n",
    "    return catalog_sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the binaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_binary(url):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        return response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_binary_to_file(binary, folder, filename):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    with open(filepath, 'bw') as f:\n",
    "        f.write(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_postupload = ('etd-06182004-122626', 'etd-09012004-114224', 'etd-0327102-091522', 'etd-0707103-142120',\n",
    "                     'etd-0710102-054039', 'etd-0409103-184148', 'etd-04152004-142117', 'etd-0830102-145811',\n",
    "                     'etd-0903103-141852', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_binaries(filenames_sheet):\n",
    "    didnt_grab = []\n",
    "    target_dir = './ETDbinaries/'\n",
    "    count = 0\n",
    "    for num, (urn, filenames_namedtuples_list) in enumerate(filenames_sheet.items()):\n",
    "        local_dir = os.path.join(target_dir, urn)\n",
    "        local_files = []\n",
    "        if os.path.isdir(local_dir):\n",
    "            local_files = os.listdir(local_dir)\n",
    "        for item in filenames_namedtuples_list:\n",
    "            if item.filename in local_files:\n",
    "                pass\n",
    "            else:\n",
    "                url = 'http://etd.lsu.edu/{}/{}'.format(\"/\".join(item.path.split('/')[3:]),\n",
    "                                                                 item.filename)\n",
    "                try:\n",
    "                    binary = retrieve_binary(url)\n",
    "                    write_binary_to_file(binary, local_dir, item.filename)\n",
    "                except:\n",
    "                    count += 1\n",
    "                    pass\n",
    "                    didnt_grab.append((urn, item.availability, item.filename))\n",
    "#                     print(urn, item.availability, item.filename)\n",
    "    print(count)\n",
    "    return didnt_grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# didnt_grab = scrape_binaries(filenames_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def what_files_arent_in_ETD_dump():\n",
    "    withheld_files = {file for a,b,c in os.walk('/media/francis/ETD/withheld/') for file in c}\n",
    "    missing_files = set()\n",
    "    for urn, availability, filename in didnt_grab:\n",
    "        if filename in withheld_files:\n",
    "            continue\n",
    "        else:\n",
    "    #         print(urn, availability, filename)\n",
    "            missing_files.add((urn, availability, filename))\n",
    "    return missing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# missing_files = what_files_arent_in_ETD_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(didnt_grab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# missing_list = sorted([*missing_files], key=lambda x:x[0])\n",
    "# for i in missing_list[:10]:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(missing_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ETD_source = [os.path.join(root, file) \n",
    "#               for root, dirs, files in os.walk('/media/francis/ETD/')\n",
    "#               for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for urn, availability, sought_filename in didnt_grab:\n",
    "#     for file in ETD_source:\n",
    "#         found_filename = os.path.split(file)[1]\n",
    "#         found_urn = file.split('/')[5]\n",
    "#         if sought_filename == found_filename and found_urn == urn:\n",
    "#             target_file = os.path.join('./ETDbinaries/', urn, found_filename)\n",
    "#             if not os.path.isfile(target_file):\n",
    "# #                 print(file, target_file)\n",
    "#                 shutil.copy2(file, target_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_writer(data, path):\n",
    "    with open(path, \"w\", newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "        for line in data:\n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatinate_keywords(keywords_sheet, urn):\n",
    "    if urn in keywords_sheet:\n",
    "        return ', '.join(nt.keyword for nt in keywords_sheet[urn] if nt.keyword)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def organize_advisors(advisors_sheet, urn):\n",
    "    Advisor = namedtuple('Advisor', ('urn', 'advisor_name', 'advisor_title',\n",
    "                                           'advisor_email', 'approval', 'timestamp'))\n",
    "    blank_Advisor = Advisor('', '', '', '', '', '')\n",
    "    Advisors_nt = advisors_sheet[urn]\n",
    "    advisors_rank = {'Committee Chair': 1, 'Committee Co-Chair': 2, 'Committee Member': 3, \"Dean's Representative\": 4}\n",
    "    alpha_Advisors = sorted(Advisors_nt, key=lambda x: x.advisor_name)\n",
    "    sorted_advisors = sorted(alpha_Advisors, key=lambda x: advisors_rank[x.advisor_title])\n",
    "    if len(sorted_advisors) > 7 and \"Dean's Representative\" in sorted_advisors[-1]:\n",
    "        sorted_advisors = sorted_advisors[:6] + sorted_advisors[-1:]\n",
    "    elif len(sorted_advisors) > 7:\n",
    "        sorted_advisors = sorted_advisors[:7]\n",
    "    elif len(sorted_advisors) < 7:\n",
    "        missing = 7 - len(sorted_advisors)\n",
    "        for i in range(missing):\n",
    "            sorted_advisors.append(blank_Advisor)\n",
    "    return sorted_advisors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip_slash_and_padding(text):\n",
    "    if not text:\n",
    "        return\n",
    "    text = text.strip()\n",
    "    if text[-1] == '/':\n",
    "        text = text[:-1]\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_null_with_nothing(text):\n",
    "    if not text:\n",
    "        return ''\n",
    "    return text.replace('NULL', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_title(catalog_sheet, main_sheet, urn):\n",
    "    if urn in catalog_sheet:\n",
    "        title = catalog_sheet[urn].Title\n",
    "        title = strip_slash_and_padding(title)\n",
    "        subtitle = catalog_sheet[urn].Subtitle\n",
    "        subtitle = strip_slash_and_padding(subtitle)\n",
    "        if title[-1] == ':':\n",
    "            title = title[:-1]\n",
    "        if subtitle:\n",
    "            csv_title = \"{}:  {}\".format(title,\n",
    "                                         subtitle)\n",
    "        else:\n",
    "            csv_title = title\n",
    "    else:\n",
    "        title = main_sheet[urn].title\n",
    "        title = strip_slash_and_padding(title)\n",
    "        csv_title = title\n",
    "    return csv_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_non_nums(text):\n",
    "    only_nums = ''\n",
    "    for i in text:\n",
    "        if i.isnumeric():\n",
    "            only_nums += i\n",
    "    return only_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_pub_date(catalog_sheet, urn):\n",
    "    if urn in catalog_sheet:\n",
    "        if catalog_sheet[urn].SeriesDate:\n",
    "            return remove_non_nums(catalog_sheet[urn].SeriesDate)\n",
    "        if catalog_sheet[urn].PubDate:\n",
    "            return remove_non_nums(catalog_sheet[urn].PubDate)\n",
    "    return remove_non_nums(main_sheet[urn].ddate)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Filenames = namedtuple('Filenames', ['urn', 'filename', 'path', 'size', 'page_count', 'availability', 'description', 'timestamp'])\n",
    "special_cases = {'etd-07062015-144158': Filenames(urn='etd-07062015-144158', filename='Moran_Thesis.pdf', path='/export/ETD-db/docs/withheld/etd-07062015-144158/withheld', size='1684241', page_count='NULL', availability='withheld', description='NULL', timestamp='2015-07-07 17:15:34'),\n",
    "                 'etd-07062015-144155': Filenames(urn='etd-07062015-144155', filename='Morris_Thesis.pdf', path='/export/ETD-db/docs/submitted/etd-07062015-144155/withheld', size='805581', page_count='NULL', availability='withheld', description='NULL', timestamp='2015-07-08 08:59:42'), \n",
    "                 'etd-04032015-080642': Filenames(urn='etd-04032015-080642', filename='wang_diss.pdf', path='/export/ETD-db/docs/withheld/etd-04032015-080642/withheld', size='6969877', page_count='NULL', availability='withheld', description='NULL', timestamp='2015-04-13 14:39:16'),\n",
    "                 'etd-08082016-164729': Filenames(urn='', filename='', path='', size='', page_count='', availability='', description='', timestamp=''),\n",
    "                 'etd-06062010-192030': Filenames(urn='', filename='', path='', size='', page_count='', availability='', description='', timestamp=''),\n",
    "                 }\n",
    "\n",
    "def find_thesis(filenames_sheet, urn):\n",
    "    if urn in special_cases:\n",
    "        return special_cases[urn]\n",
    "    largest_pdf_file = None\n",
    "    for file in filenames_sheet[urn]:\n",
    "        extension = file.filename.split('.')[-1].lower().strip()\n",
    "        if extension != 'pdf':\n",
    "            continue\n",
    "        if not largest_pdf_file:\n",
    "            largest_pdf_file = file\n",
    "        elif int(file.size) > int(largest_pdf_file.size):\n",
    "            largest_pdf_file = file\n",
    "    return largest_pdf_file   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_month_day = re.compile(r'^(\\d{4})[/.-](\\d{1,2})[/.-](\\d{1,2})$')\n",
    "year_only = re.compile(r'^(\\d{4})$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_defense_date(main_sheet, urn):\n",
    "    if main_sheet[urn].ddate:\n",
    "        return main_sheet[urn].ddate\n",
    "    return ''\n",
    "\n",
    "def find_submission_date(main_sheet, urn):\n",
    "    if main_sheet[urn].sdate:\n",
    "        return main_sheet[urn].sdate\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_thesis_url(urn):\n",
    "    thesis_file = find_thesis(filenames_sheet, urn)\n",
    "    return 'https://dl.dropboxusercontent.com/u/302551934/{}/{}'.format(urn, thesis_file.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_set_all_urns(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet):\n",
    "    all_urns = set()\n",
    "    for sheet in (main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet):\n",
    "        for urn in sheet:\n",
    "            all_urns.add(urn)\n",
    "    all_urns.remove(None)  #\n",
    "    return all_urns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "overlooked_degrees = set()\n",
    "\n",
    "def read_legacy_dept_map():\n",
    "    legacy_current = dict()\n",
    "    sourcepath = 'data/LegacyNames.csv'\n",
    "    with open(sourcepath, encoding='utf-8') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter='\\t')\n",
    "        for num, row in enumerate(csvreader):\n",
    "            if num == 0:\n",
    "                headers = (i for i in row)\n",
    "            current, legacy = row[0].strip(), row[1].strip()\n",
    "            if current and current != 'Program no longer active':\n",
    "                if legacy not in legacy_current:\n",
    "                    if legacy not in ('New', ):\n",
    "                        legacy_current[legacy] = current\n",
    "                else:\n",
    "                    print(legacy, 'has two mappings')\n",
    "    return legacy_current\n",
    "\n",
    "def lookup_current_dept(legacy_dept):\n",
    "    legacy_current = read_legacy_dept_map()\n",
    "    if legacy_dept in legacy_current:\n",
    "        return legacy_current[legacy_dept]\n",
    "    else:\n",
    "        overlooked_degrees.add(legacy_dept)\n",
    "        return legacy_dept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_matching_degree_abbrevs = dict()\n",
    "\n",
    "abbr_degree = {\"MPT\": \"Master of Physical Therapy (MPT)\",\n",
    "    \"MUP\": \"Master of Urban Planning (MUP)\",\n",
    "    \"DM\": \"Doctor of Music (DM)\",\n",
    "    \"MTS\": \"Master of Theological Studies (MTS)\",\n",
    "    \"AuD\": \"Doctor of Audiology (AuD)\",\n",
    "    \"MSEE\": \"Master of Science in Electrical Engineering (MSEE)\",\n",
    "    \"MSIB\": \"Master of Science in International Business (MSIB)\",\n",
    "    \"MCSM\": \"Master of Construction Science and Management (MCSM)\",\n",
    "    \"PsyD\": \"Doctor of Psychology (PsyD)\",\n",
    "    \"MSEM\": \"Master of Science in Engineering Management (MSEM)\",\n",
    "    \"MSMSE\": \"Master of Science in Materials Science and Engineering (MSMSE)\",\n",
    "    \"RhD\": \"Doctor of Rehabilitation (RhD)\",\n",
    "    \"MATE\": \"Master of Arts in the Teaching of English (MATE)\",\n",
    "    \"DPT\": \"Doctor of Physical Therapy (DPT)\",\n",
    "    \"MSAgE\": \"Master of Science in Agricultural Engineering (MSAgE)\",\n",
    "    \"PhDOtol\": \"PhD Otolaryngology (PhDOtol)\",\n",
    "    \"MSHRM\": \"Master of Science in Human Resources Management (MSHRM)\",\n",
    "    \"MIM\": \"Master of International Management (MIM)\",\n",
    "    \"DMin\": \"Doctor of Ministry (DMin)\",\n",
    "    \"MSIE\": \"Master of Science in Industrial Engineering (MSIE)\",\n",
    "    \"MSISE\": \"Master of Science in Infrastructure Systems Engineering (MSISE)\",\n",
    "    \"DPA\": \"Doctor of Public Administration (DPA)\",\n",
    "    \"HSOP\": \"Doctor of Philosophy in Health Services Research (HSOP)\",\n",
    "    \"MMatSE\": \"Master of Materials Science and Engineering (MMatSE)\",\n",
    "    \"MAeroE\": \"Master of Aeronautical Engineering (MAeroE)\",\n",
    "    \"MMT\": \"Master in Management of Technology (MMT)\",\n",
    "    \"MSJ\": \"Master of Science in Jurisprudence (MSJ)\",\n",
    "    \"MHP\": \"Master of Historic Preservation (MHP)\",\n",
    "    \"DEng\": \"Doctor of Engineering (DEng)\",\n",
    "    \"MBA\": \"Master of Business Administration (MBA)\",\n",
    "    \"MRED\": \"Master of Real Estate Development (MRED)\",\n",
    "    \"MCTE\": \"Master of Career and Technology Education (MCTE)\",\n",
    "    \"MSAeroE\": \"Master of Science in Aerospace Engineering (MSAeroE)\",\n",
    "    \"MAR\": \"Master of Arts in Religion (MAR)\",\n",
    "    \"MST\": \"Master's of Science in Teaching (MST)\",\n",
    "    \"MJS\": \"Master of Judicial Studies (MJS)\",\n",
    "    \"MALA\": \"Master of Arts in Liberal Arts (MALA)\",\n",
    "    \"MSETM\": \"Master of Science in Environmental Technology Management (MSETM)\",\n",
    "    \"MSHTM\": \"Master of Science in Hospitality and Tourism Management (MSHTM)\",\n",
    "    \"Th.M\": \"Master of Theology (Th.M)\",\n",
    "    \"MSM\": \"Master of Science in Management (MSM)\",\n",
    "    \"MCRP\": \"Master of City and Regional Planning (MCRP)\",\n",
    "    \"MBS\": \"Master of Building Science (MBS)\",\n",
    "    \"MAIS\": \"Master of Arts in Interdisciplinary Studies (MAIS)\",\n",
    "    \"DBA\": \"Doctor of Business Administration (DBA)\",\n",
    "    \"MPH\": \"Master of Public Health (MPH)\",\n",
    "    \"MIDS\": \"Master of Interdisciplinary Studies (MIDS)\",\n",
    "    \"MPA/JD\": \"Master of Public Administration/Juris Doctorate (MPA/JD)\",\n",
    "    \"PhD\": \"Doctor of Philosophy (PhD)\",\n",
    "    \"DMgt\": \"Doctor of Management (DMgt)\",\n",
    "    \"MCIS\": \"Master of Computer and Information Science (MCIS)\",\n",
    "    \"MAE\": \"Master of Arts in Education (MAE)\",\n",
    "    \"MHD\": \"Master of Human Development (MHD)\",\n",
    "    \"MM\": \"Master of Music (MM)\",\n",
    "    \"MGS\": \"Master of General Studies (MGS)\",\n",
    "    \"MSN\": \"Master of Science in Nursing (MSN)\",\n",
    "    \"M.Div\": \"Master of Divinity (M.Div)\",\n",
    "    \"MAC\": \"Master of Arts in Counseling (MAC)\",\n",
    "    \"MCJ\": \"Master of Criminal Justice (MCJ)\",\n",
    "    \"MFR\": \"Master of Forest Resources (MFR)\",\n",
    "    \"MSSS\": \"Master of Science in Computer Science (MSCS)\",\n",
    "    \"MSA\": \"Master of Science in Administration (MSA)\",\n",
    "    \"MURP\": \"Master of Urban and Regional Planning (MURP)\",\n",
    "    \"MAS\": \"Master in Advanced Studies (MAS)\",\n",
    "    \"ND\": \"Doctor of Nursing (ND)\",\n",
    "    \"ME\": \"Master of Engineering (ME)\",\n",
    "    \"MSCRP\": \"Master of Science in Community and Regional Planning (MSCRP)\",\n",
    "    \"MArch\": \"Master of Architecture (MArch)\",\n",
    "    \"MLIS\": \"Master of Library and Information Science (MLIS)\",\n",
    "    \"MSOtol\": \"MS Otolaryngology (MSOtol)\",\n",
    "    \"MLS\": \"Master of Library Science/Master of Life Sciences (MLS)\",\n",
    "    \"MSMANFE\": \"Master of Science in Manufacturing Engineering (MSMANFE)\",\n",
    "    \"MSSE\": \"Master of Science and Software Engineering (MSSE)\",\n",
    "    \"MEngr\": \"Master of Engineering (MEngr)\",\n",
    "    \"MSB\": \"Masters of Science in Bioscience (MSB)\",\n",
    "    \"PED\": \"Doctor of Physical Education (PED)\",\n",
    "    \"MFA\": \"Master of Fine Arts (MFA)\",\n",
    "    \"MMC\": \"Master of Mass Communication (MMC)\",\n",
    "    \"MSBAE\": \"Master of Science in Biological and Agricultural Engineering (MSBAE)\",\n",
    "    \"MAgEd\": \"Master of Agricultural Education (MAgEd)\",\n",
    "    \"MSECE\": \"Master of Science in Electrical and Computer Engineering (MSECE)\",\n",
    "    \"DMD\": \"Doctor of Dental Medicine (DMD)\",\n",
    "    \"MSMatSE\": \"Master of Science in Material Science Engineering (MSMatSE)\",\n",
    "    \"MAPC\": \"Master of Arts in Pastoral Counseling (MAPC)\",\n",
    "    \"MSEd\": \"Master of Science in Education (MSEd)\",\n",
    "    \"DPDS\": \"Doctor of Planning and Development Studies (DPDS)\",\n",
    "    \"MRP\": \"Master of Regional Planning (MRP)\",\n",
    "    \"MNS\": \"Master of Natural Sciences (MNS)\",\n",
    "    \"EdD\": \"Doctor of Education (EdD)\",\n",
    "    \"DrPH\": \"Doctor of Public Health (DrPH)\",\n",
    "    \"DNS\": \"Doctor of Nursing Science (DNS)\",\n",
    "    \"MSIEOR\": \"Master of Science in Industrial Engineering and Operations Research (MSIEOR)\",\n",
    "    \"MAT\": \"Master of Arts in Teaching (MAT)\",\n",
    "    \"MEE\": \"Master of Electrical Engineering (MEE)\",\n",
    "    \"MS\": \"Master of Science (MS)\",\n",
    "    \"MSECO\": \"Master of Science in Economics (MSECO)\",\n",
    "    \"MLA\": \"Master of Landscape Architecture (MLA)\",\n",
    "    \"PhDSurg\": \"PhD Surgergy (PhDSurg)\",\n",
    "    \"MSES\": \"Master of Science in Engineering Science (MSES)\",\n",
    "    \"MHI\": \"Masters of Health Informatics (MHI)\",\n",
    "    \"MSME\": \"Master of Science in Mechanical Engineering (MSME)\",\n",
    "    \"MMUS\": \"Master of Music (MMUS)\",\n",
    "    \"MSW\": \"Master of Social Work (MSW)\",\n",
    "    \"MME\": \"Master of Music Education (MME)\",\n",
    "    \"DMA\": \"Doctor of Musical Arts (DMA)\",\n",
    "    \"MPA\": \"Master of Public Administration (MPA)\",\n",
    "    \"DA\": \"Doctor of Arts (DA)\",\n",
    "    \"MApStat\": \"Master of Applied Statistics (MApStat)\",\n",
    "    \"MSP\": \"Master of Science in Planning (MSP)\",\n",
    "    \"MPP\": \"Master of Public Policy (MPP)\",\n",
    "    \"MSExpSurg\": \"Medical Surgeon in Experimental Surgery (MSExpSurg)\",\n",
    "    \"EdS\": \"Education Specialist (EdS)\",\n",
    "    \"MF\": \"Master of Forestry (MF)\",\n",
    "    \"MPlan\": \"Master of Planning (MPlan)\",\n",
    "    \"MBT\": \"Master of Business Taxation (MBT)\",\n",
    "    \"HSD\": \"Doctor of Health and Safety (HSD)\",\n",
    "    \"MHRD\": \"Master of Human Resource Development (MHRD)\",\n",
    "    \"MSPH\": \"Master of Science in Public Health (MSPH)\",\n",
    "    \"MChE\": \"Master of Chemical Engineering (MChE)\",\n",
    "    \"MSPE\": \"Master of Science in Petroleum Engineering (MSPE)\",\n",
    "    \"MCompE\": \"Master of Computer Engineering (MCompE)\",\n",
    "    \"MT\": \"Master in Taxation (MT)\",\n",
    "    \"MAcc\": \"Master of Accounting (MAcc)\",\n",
    "    \"MPM\": \"Master of Public Management (MPM)\",\n",
    "    \"MSE\": \"Master of Science in Engineering (MSE)\",\n",
    "    \"DME\": \"Doctor of Music Education (DME)\",\n",
    "    \"DSW\": \"Doctor of Social Work (DSW)\",\n",
    "    \"MSCE\": \"Master of Science in Civil Engineering (MSCE)\",\n",
    "    \"DVM\": \"Doctor of Veterinary Medicine (DVM)\",\n",
    "    \"MCE\": \"Master of Civil Engineering (MCE)\",\n",
    "    \"MES\": \"Master of Environmental Studies (MES)\",\n",
    "    \"MECom\": \"Master of Electronic Commerce (MECom)\",\n",
    "    \"MHA\": \"Master of Health Administration (MHA)\",\n",
    "    \"PharmD\": \"Doctor of Pharmacy (PharmD)\",\n",
    "    \"MA\": \"Master of Arts (MA)\",\n",
    "    \"Ded\": \"Doctor of Education (Ded)\",\n",
    "    \"MEnvE\": \"Master of Environmental Engineering (MEnvE)\",\n",
    "    \"ReD\": \"Doctor of Recreation (ReD)\",\n",
    "    \"JD\": \"Juris Doctorate (JD)\",\n",
    "    \"MSBiosyAgE\": \"Master of Science in Biosystems and Agricultural Engineering (MSBiosyAgE)\",\n",
    "    \"PMBA\": \"Professional Master of Business Administration (PMBA)\",\n",
    "    \"MHAMS\": \"Master of Historical Administration and Museum Studies (MHAMS)\",\n",
    "    \"MSIS\": \"Master of Science in Interdisciplinary Studies (MSIS)\",\n",
    "    \"IMES\": \"International Master of Environmental Sciences (IMES)\",\n",
    "    \"MSChE\": \"Master of Science in Chemical Engineering (MSChE)\",\n",
    "    \"MPAcc\": \"Master of Professional Accounting (MPAcc)\",\n",
    "    \"MGIS\": \"Master of Geographic Information Science (MGIS)\",\n",
    "    \"MBioSci\": \"Master of Biological Science (MBioSci)\",\n",
    "    \"MCM\": \"Master of Construction Management (MCM)\",\n",
    "    \"MSMS\": \"Master of Science in Medical Sciences (MSMS)\",\n",
    "    \"MD\": \"Medical Doctor (MD)\",\n",
    "    \"Medical Science\": \"Doctor of Philosophy (Medical Science)\",\n",
    "    \"MGeoE\": \"Master of Geomechanics Engineering (MGeoE)\",\n",
    "    \"MEd\": \"Master of Education (MEd)\",\n",
    "    \"MAM\": \"Master in Agricultural Management (MAM)\",\n",
    "    \"MPRTM\": \"Master of Parks, Recreation and Tourism Management (MPRTM)\",\n",
    "    \"MAgr\": \"Master of Agriculture (MAgr)\",\n",
    "    }\n",
    "\n",
    "def expand_degree_type(degree_name):\n",
    "    if degree_name in abbr_degree:\n",
    "        return abbr_degree[degree_name]\n",
    "    else:\n",
    "        if degree_name not in non_matching_degree_abbrevs:\n",
    "            non_matching_degree_abbrevs[degree_name] = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_email(text):\n",
    "    if not text:\n",
    "        return ''\n",
    "    emails = text.split(',')\n",
    "    for i in emails:\n",
    "        if 'lsu.edu' not in i and len(i):\n",
    "            return i.strip()\n",
    "    else:\n",
    "        if len(emails[0]) == 0:\n",
    "            print(emails)\n",
    "        return emails[0].strip()\n",
    "\n",
    "def lookup_email(urn):\n",
    "    pack = main_sheet[urn]\n",
    "    return split_email(pack.author_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lookup_hide_email(urn):\n",
    "    pack = main_sheet[urn]\n",
    "    translation = {'yes': 'false', 'no': 'true', 'on': 'true'}\n",
    "    yes_or_no = pack.publish_email.lower()\n",
    "    return translation[yes_or_no]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# current_department & department mapped -- we need department & legacy department.\n",
    "\n",
    "def build_csv(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet):\n",
    "    all_urns = make_set_all_urns(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet)\n",
    "    for papertype in ('thesis', 'dissertation', 'major_paper'):\n",
    "        csv_data = []\n",
    "        csvfieldnames = [\"title\",\n",
    "                         \"fulltext_url\",\n",
    "                         \"author1_fname\",\n",
    "                         'author1_mname',\n",
    "                         'author1_lname',\n",
    "                         'author1_suffix',\n",
    "                         'author1_email',\n",
    "                         'hide_author_email',\n",
    "                         'author1_institution',\n",
    "                         'advisor1_title',\n",
    "                         'advisor1',\n",
    "                         \"advisor1_email\",\n",
    "                         'advisor2_title',\n",
    "                         'advisor2',\n",
    "                         \"advisor2_email\",\n",
    "                         'advisor3_title',\n",
    "                         'advisor3',\n",
    "                         \"advisor3_email\",\n",
    "                         'advisor4_title',\n",
    "                         'advisor4',\n",
    "                         \"advisor4_email\",\n",
    "                         'advisor5_title',\n",
    "                         'advisor5',\n",
    "                         \"advisor5_email\",\n",
    "                         'advisor6_title',\n",
    "                         'advisor6',\n",
    "                         \"advisor6_email\",\n",
    "                         'advisor7_title',\n",
    "                         'advisor7',\n",
    "                         \"advisor7_email\",\n",
    "                         \"document_type\",\n",
    "                         'degree_name',\n",
    "                         'legacy_department',\n",
    "                         'department',\n",
    "                         'disciplines',\n",
    "                         'keywords',\n",
    "                         'abstract',\n",
    "                         'publication_date',\n",
    "                         'defense_date',\n",
    "                         'submission_date',\n",
    "                         'availability',\n",
    "                         'availability_description',\n",
    "                         'urn',\n",
    "                         'file_name',\n",
    "                         'file_size',\n",
    "                        ]\n",
    "        csv_data.append(csvfieldnames)\n",
    "\n",
    "        papertype_urns = [urn for urn in all_urns if main_sheet[urn].dtype.lower() == papertype]\n",
    "        for urn in papertype_urns:\n",
    "            csv_title = combine_title(catalog_sheet, main_sheet, urn)\n",
    "            csv_urn = urn\n",
    "            fulltext_url = parse_thesis_url(urn)\n",
    "            csv_first_name = main_sheet[urn].first_name\n",
    "            csv_middle_name = main_sheet[urn].middle_name\n",
    "            csv_last_name = main_sheet[urn].last_name\n",
    "            csv_suffix = main_sheet[urn].suffix\n",
    "            csv_suffix = replace_null_with_nothing(csv_suffix)\n",
    "            csv_author_email = lookup_email(urn)\n",
    "            csv_hide_author_email = lookup_hide_email(urn)\n",
    "            sorted_advisors = organize_advisors(advisors_sheet, urn)\n",
    "            csv_document_type = main_sheet[urn].dtype.lower()\n",
    "            csv_degree = expand_degree_type(main_sheet[urn].degree)\n",
    "            csv_legacy_department = main_sheet[urn].department\n",
    "            csv_department = lookup_current_dept(main_sheet[urn].department)\n",
    "            csv_disciplines = \"not yet implemented\"\n",
    "            csv_keywords = concatinate_keywords(keywords_sheet, urn)\n",
    "            csv_abstract = main_sheet[urn].abstract\n",
    "            csv_publication_date = find_pub_date(catalog_sheet, urn)\n",
    "            csv_defense_date = find_defense_date(main_sheet, urn)\n",
    "            csv_submission_date = find_submission_date(main_sheet, urn)\n",
    "            csv_availability = main_sheet[urn].availability\n",
    "            csv_availability_desc = main_sheet[urn].availability_description\n",
    "            csv_filename = find_thesis(filenames_sheet, urn).filename\n",
    "            csv_filesize = find_thesis(filenames_sheet, urn).size\n",
    "\n",
    "\n",
    "            if urn in filenames_sheet:\n",
    "                filename = filenames_sheet[urn][0].filename\n",
    "            else:\n",
    "                filename = ''\n",
    "            csv_data.append([csv_title,\n",
    "                             fulltext_url,\n",
    "                             csv_first_name,\n",
    "                             csv_middle_name,\n",
    "                             csv_last_name,\n",
    "                             csv_suffix,\n",
    "                             csv_author_email,\n",
    "                             csv_hide_author_email,\n",
    "                             'Louisiana State University and Agricultural and Mechanical College',\n",
    "                             sorted_advisors[0].advisor_title,\n",
    "                             sorted_advisors[0].advisor_name,\n",
    "                             sorted_advisors[0].advisor_email,\n",
    "                             sorted_advisors[1].advisor_title,\n",
    "                             sorted_advisors[1].advisor_name,\n",
    "                             sorted_advisors[1].advisor_email,\n",
    "                             sorted_advisors[2].advisor_title,\n",
    "                             sorted_advisors[2].advisor_name,\n",
    "                             sorted_advisors[2].advisor_email,\n",
    "                             sorted_advisors[3].advisor_title,\n",
    "                             sorted_advisors[3].advisor_name,\n",
    "                             sorted_advisors[3].advisor_email,\n",
    "                             sorted_advisors[4].advisor_title,\n",
    "                             sorted_advisors[4].advisor_name,\n",
    "                             sorted_advisors[4].advisor_email,\n",
    "                             sorted_advisors[5].advisor_title,\n",
    "                             sorted_advisors[5].advisor_name,\n",
    "                             sorted_advisors[5].advisor_email,\n",
    "                             sorted_advisors[6].advisor_title,\n",
    "                             sorted_advisors[6].advisor_name,\n",
    "                             sorted_advisors[6].advisor_email,\n",
    "                             csv_document_type,\n",
    "                             csv_degree,\n",
    "                             csv_legacy_department,\n",
    "                             csv_department,\n",
    "                             csv_disciplines,\n",
    "                             csv_keywords,\n",
    "                             csv_abstract,\n",
    "                             csv_publication_date,\n",
    "                             csv_defense_date,\n",
    "                             csv_submission_date,\n",
    "                             csv_availability,\n",
    "                             csv_availability_desc,\n",
    "                             urn,\n",
    "                             csv_filename,\n",
    "                             csv_filesize,\n",
    "                             ])\n",
    "    #     print(csv_data)\n",
    "        csv_writer(csv_data, '../../scrap{}.csv'.format(papertype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if __name__ == '__main__':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "available_wb = read_workbook('available')\n",
    "submitted_wb = read_workbook('submitted')\n",
    "withheld_wb = read_workbook('withheld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merges the matching sheets from all 3 workbooks into one datastructure per sheet-type.\n",
    "all_db_workbooks = (available_wb, submitted_wb, withheld_wb)\n",
    "\n",
    "main_sheet = parse_main_sheet(all_db_workbooks)\n",
    "filenames_sheet = parse_filename_sheet(all_db_workbooks)\n",
    "keywords_sheet = parse_keyword_sheet(all_db_workbooks)\n",
    "advisors_sheet = parse_advisors_sheet(all_db_workbooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catalog_sheet = parse_catalog_sheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "build_csv(main_sheet, catalog_sheet, filenames_sheet, keywords_sheet, advisors_sheet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# overlooked degrees are ones that aren't mapped legacy dept to current dept.  The legacy dept name is\n",
    "# therefore transfering over to the current dept name.\n",
    "\n",
    "# print(overlooked_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# items in main sheet but not in catalog\n",
    "\n",
    "# main_sheet_urns = {i for i in main_sheet}\n",
    "# catalog_sheet_urns = {i for i in catalog_sheet}\n",
    "# in_main_not_catalog = main_sheet_urns - catalog_sheet_urns\n",
    "\n",
    "# print(len(in_main_not_catalog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for urn, a_list in filenames_sheet.items():\n",
    "#     for nt in a_list:\n",
    "#         if nt.availability not in ('available', 'unrestricted'):\n",
    "#             print(urn, nt.availability, nt.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "# how often is adate a different year from pubDate?\n",
    "\n",
    "count = 0\n",
    "for urn, pack in main_sheet.items():\n",
    "    if urn in catalog_sheet:\n",
    "        if catalog_sheet[urn].PubDate:\n",
    "            if remove_non_nums(catalog_sheet[urn].PubDate) != remove_non_nums(pack.adate)[:4]:\n",
    "                count += 1\n",
    "#                 print(urn, remove_non_nums(catalog_sheet[urn].PubDate), pack.rdate[:4])\n",
    "        elif catalog_sheet[urn].SeriesDate:\n",
    "            if remove_non_nums(catalog_sheet[urn].SeriesDate) != remove_non_nums(pack.adate)[:4]:\n",
    "                count += 1\n",
    "#                 print(urn, remove_non_nums(catalog_sheet[urn].SeriesDate), pack.rdate[:4])\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listed_filenames = set()\n",
    "duplicate_filenames = dict()\n",
    "\n",
    "for urn, item_list in filenames_sheet.items():\n",
    "    for item in item_list:\n",
    "        if item.filename in listed_filenames:\n",
    "            if item.filename in duplicate_filenames:\n",
    "                duplicate_filenames[item.filename] += 1\n",
    "            else:\n",
    "                duplicate_filenames[item.filename] = 1\n",
    "        else:\n",
    "            listed_filenames.add(item.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplicate_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# displays which binaries share a name\n",
    "\n",
    "# count = 0\n",
    "# for n in range(12):\n",
    "#     countdown = 13 - n\n",
    "#     print('{} files with the name:'.format(countdown))\n",
    "#     for k, v in duplicate_filenames.items():\n",
    "#         if v == countdown:\n",
    "#             print('\\t', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8398\n"
     ]
    }
   ],
   "source": [
    "print(len(main_sheet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for urn in catalog_sheet:\n",
    "    if not year_only.search(find_pub_date(catalog_sheet, urn)):\n",
    "        print(urn, main_sheet[urn].sdate, main_sheet[urn].ddate, main_sheet[urn].rdate, main_sheet[urn].adate)\n",
    "    if not year_month_day.search(find_defense_date(main_sheet, urn)):\n",
    "        print(urn, main_sheet[urn].sdate, main_sheet[urn].ddate, main_sheet[urn].rdate, main_sheet[urn].adate)\n",
    "    if not year_month_day.search(find_submission_date(main_sheet, urn)):\n",
    "        print(urn, main_sheet[urn].sdate, main_sheet[urn].ddate, main_sheet[urn].rdate, main_sheet[urn].adate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items_extensions = dict()\n",
    "for urn, pack in filenames_sheet.items():\n",
    "    filetypes_found = dict()\n",
    "    for bunch in pack:\n",
    "        extension = bunch.filename.split('.')[-1].strip().lower()\n",
    "        if extension in filetypes_found:\n",
    "            filetypes_found[extension] += 1\n",
    "        else:\n",
    "            filetypes_found[extension] = 1\n",
    "    items_extensions[urn] = filetypes_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "# looking for items with supplementals\n",
    "\n",
    "has_supplementals = dict()\n",
    "\n",
    "for urn, list_of_filenamedtuples in filenames_sheet.items():\n",
    "    if len(list_of_filenamedtuples) > 1:\n",
    "        has_supplementals[urn] = list_of_filenamedtuples\n",
    "\n",
    "print(len(has_supplementals))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# has no pdf, or more than one pdf\n",
    "\n",
    "# for urn, extensions_count in items_extensions.items():\n",
    "#     if 'pdf' not in extensions_count:\n",
    "#         print('{} has no pdf  {}'.format(urn, extensions_count))\n",
    "#         break\n",
    "#     elif extensions_count['pdf'] > 1:\n",
    "#         print('{} has {} pdfs  {}'.format(urn, extensions_count['pdf'], extensions_count))\n",
    "#         print(*('{} \\t{}\\n'.format(i.filename, i.size) for i in filenames_sheet[urn] if '.pdf' in i.filename.lower()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
